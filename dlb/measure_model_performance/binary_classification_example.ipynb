{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Classification problem\n",
        "\n",
        "This is an example of a classification problem.\n",
        "The results are used for the notebooks on measuring the performance of classification models (for the book on DL).\n",
        "\n",
        "**Import libraries** and **set the seed**"
      ],
      "metadata": {
        "id": "JN4dUc60l1tj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsjCzrLQjpyW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "nint = 113\n",
        "np.random.seed(nint)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the data\n",
        "\n",
        "Breast cancer data:\n",
        "\n",
        "- binary classification\n",
        "- 30 features, numeric"
      ],
      "metadata": {
        "id": "R6w5vJPJtOub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "(X, y) = load_breast_cancer(return_X_y=True)"
      ],
      "metadata": {
        "id": "hOHtEZ07mJe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"N. of examples\", len(y))"
      ],
      "metadata": {
        "id": "t1KJqoZtmfbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "metadata": {
        "id": "bJhT7HZnxAiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Subset columns\n",
        "\n",
        "Take a random subset of features:"
      ],
      "metadata": {
        "id": "UTonkj6UtdBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "n_vars = 8 ## n. of features to select (randomly)\n",
        "lst = list(range(0,X.shape[1]))"
      ],
      "metadata": {
        "id": "btXqw_a-sajM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(nint)\n",
        "selected_cols = random.sample(lst, n_vars)"
      ],
      "metadata": {
        "id": "fwWwP0K_wHKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X[:,selected_cols]"
      ],
      "metadata": {
        "id": "9QDLgT9_tI38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data normalization\n",
        "\n",
        "Center and scale the matrix of features `X`"
      ],
      "metadata": {
        "id": "u4gvzCjhto7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(nint)\n",
        "print(random.random())"
      ],
      "metadata": {
        "id": "C_E9oQJav7HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg = np.mean(X, axis=0)\n",
        "std = np.std(X, axis=0)"
      ],
      "metadata": {
        "id": "xvxq3bVGo1hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm = (X-avg)/std"
      ],
      "metadata": {
        "id": "s1xw33jDqSLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean of 1st feature:\",X_norm[:,0].mean())\n",
        "print(\"Standard deviation of 1st feature:\", X_norm[:,0].std())"
      ],
      "metadata": {
        "id": "1ZufW1yotxdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training / test data split\n",
        "\n",
        "Randomly split the data in training (80%) and test set (20%)"
      ],
      "metadata": {
        "id": "on7gXbXguAS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=nint)"
      ],
      "metadata": {
        "id": "kAEpZfJyntc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"N. of training examples:\", len(X_train))"
      ],
      "metadata": {
        "id": "OsA8mVtbnwIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"N. of test examples:\", len(X_test))"
      ],
      "metadata": {
        "id": "XAfTr7JauS5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0:10]"
      ],
      "metadata": {
        "id": "Pe53oCv2n1s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic regression model\n",
        "\n",
        "Fir the logistic regression model:"
      ],
      "metadata": {
        "id": "hepiV8FIuYkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg = LogisticRegression(random_state=nint)"
      ],
      "metadata": {
        "id": "AMUbAkY2nDMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model with data\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "UGMqLyYuofyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get predictions on the test set"
      ],
      "metadata": {
        "id": "Ro5uH3uBudU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "oJt8SHBtq1ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Measure model performance"
      ],
      "metadata": {
        "id": "MvuuIoS6ugof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the metrics class\n",
        "from sklearn import metrics\n",
        "\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix"
      ],
      "metadata": {
        "id": "pF1wzHm2q4sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_probs = logreg.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "vqlJ9P5s4yLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this cell mounts the user's google drive in the specified folder,\n",
        "#but only once (doing more than once would generate an error)\n",
        "import os\n",
        "\n",
        "gdrive_folder = '/content/gdrive'\n",
        "project_folder = '/content/gdrive/MyDrive/projects/book_DL' ## !! IMPORTANT: change this depending on data iteration !!\n",
        "\n",
        "if not os.path.isdir(gdrive_folder):\n",
        "  from google.colab import drive\n",
        "  drive.mount(gdrive_folder)"
      ],
      "metadata": {
        "id": "TfkxJK6w_o8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_all = np.vstack((y_test, y_pred)).T"
      ],
      "metadata": {
        "id": "oPQqfkBvBnyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(np.hstack((y_all, lr_probs)), columns=['y_test', 'y_pred', 'prob_0', 'prob1'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9b7-A2hAAami"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "VHlJemK8cJ2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def writeout_results(res, filename):\n",
        "\n",
        "    basedir = os.path.dirname(filename)\n",
        "    if os.path.isdir(basedir):\n",
        "          res.to_csv(filename, mode='w', header=True, index=False)\n",
        "          return \"Creating file '{}' and writing results to it\".format(os.path.basename(filename))\n",
        "    else:\n",
        "          os.makedirs(os.path.dirname(filename))\n",
        "          res.to_csv(filename, mode='w', header=True, index=False)\n",
        "          return \"Creating folder '{}' and writing results to file {}\".format(basedir, os.path.basename(filename))"
      ],
      "metadata": {
        "id": "D3_rdClUD7Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## the model object is used to extract predictions\n",
        "## if not reinstantiated, I believe that the model object keeps being over\n",
        "## epochs in the above for loop; therefore the model object after the loop\n",
        "## containes the fully trained model to be used for predictions\n",
        "\n",
        "print(\" - saving predictions\")\n",
        "fname = os.path.join(project_folder, \"predictions.csv\")\n",
        "print(\"writing results to: \", fname)\n",
        "writeout_results(df, fname)"
      ],
      "metadata": {
        "id": "PR1FnOsiAJUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}