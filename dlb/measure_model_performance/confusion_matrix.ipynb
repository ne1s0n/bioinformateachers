{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix\n",
        "\n",
        "In this notebook, we illustrate how to:\n",
        "\n",
        "1. build the confusion matrix\n",
        "2. plot the confusion matrix\n",
        "3. extract the basic error rates from the confusion matrix"
      ],
      "metadata": {
        "id": "IM3kYD6kfSt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the libraries"
      ],
      "metadata": {
        "id": "g-wJZSOqbPJ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq12QvKqfQKS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "We are using results from a mock binary classification problem.\n",
        "This was based on the [breast cancer Wisconsin dataset](https://github.com/scikit-learn/scikit-learn/blob/6e9039160f0dfc3153643143af4cfdca941d2045/sklearn/datasets/data/breast_cancer.csv) from the Python library `sklearn`.\n",
        "\n",
        "In this dataset, the objective is to diagnose the status of breast cancer:\n",
        "\n",
        "- `0`: malignant cancer\n",
        "- `1`: benign cancer\n",
        "\n",
        "The dataset contains **569 examples**:\n",
        "\n",
        "- 212 malignant\n",
        "- 357 benign\n",
        "\n",
        "And the prediction (classification) is based on 30 numeric features related to the cancer lesions (size, shape etc.: full description can be found [here](https://scikit-learn.org/1.5/datasets/toy_dataset.html#breast-cancer-dataset))"
      ],
      "metadata": {
        "id": "LKt3NNJ6bXiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually, in this example we used a random subset of the 30 features, by selecting 8 features: in this way, the problem was harder, and we obtained more classification errors, which is instrumental to the illustration of different metrics to measure model performance."
      ],
      "metadata": {
        "id": "3VEszy-dbf7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_URL = 'https://raw.githubusercontent.com/ne1s0n/bioinformateachers/refs/heads/main/dlb/data/predictions.csv'"
      ],
      "metadata": {
        "id": "LWNyq_hWU7Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['y_test', 'y_pred']\n",
        "\n",
        "bc_data = pd.read_csv(DATASET_URL, usecols=columns)\n",
        "bc_data.head()"
      ],
      "metadata": {
        "id": "llnG_U9TU9wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predictions = bc_data['y_pred']\n",
        "observations = bc_data['y_test']\n",
        "\n",
        "predicted_labels = np.where(predictions == 1.0, \"case\", \"control\")\n",
        "target_labels = np.where(observations == 1.0, \"case\", \"control\")"
      ],
      "metadata": {
        "id": "DpCktl3HXg-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import index\n",
        "\n",
        "labs, counts = np.unique(predicted_labels, return_counts=True)\n",
        "dict1 = {k:v for (k,v) in zip(labs,counts)}\n",
        "dict1['set'] = 'predictions'\n",
        "\n",
        "labs, counts = np.unique(target_labels, return_counts=True)\n",
        "dict2 = {k:v for (k,v) in zip(labs,counts)}\n",
        "dict2['set'] = 'observations'\n",
        "\n",
        "\n",
        "pd.DataFrame.from_records([dict1,dict2])"
      ],
      "metadata": {
        "id": "U_QnsoxzRjIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "      | pred - | pred +\n",
        "------|--------|--------\n",
        "obs - |   TN   |   FP\n",
        "obs + |   FN   |   TP\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Kt2nM805XwLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat_df = confusion_matrix(predicted_labels, target_labels, labels=[\"control\",\"case\"])\n",
        "print(conf_mat_df)"
      ],
      "metadata": {
        "id": "qz1ziMsYQMNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sanity check\n",
        "## let's get the n. of true positives (y_test == 1 AND y_pred == 1)\n",
        "bc_data.loc[(bc_data['y_test'] == 1) & (bc_data['y_pred'] == 1)].shape[0]"
      ],
      "metadata": {
        "id": "_jnVpffAYURa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sn.heatmap(conf_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Azu-CTZnEVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat_norm = confusion_matrix(target_labels, predicted_labels, normalize='true', labels=[\"control\",\"case\"])\n",
        "print(conf_mat_norm)"
      ],
      "metadata": {
        "id": "TrhRmbtanYZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "Y_nNPxmjPnit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat_norm)"
      ],
      "metadata": {
        "id": "tejos4I7P8U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disp.plot(xticks_rotation=45)"
      ],
      "metadata": {
        "id": "ZlC0mkQ2QA9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(target_labels, predicted_labels)"
      ],
      "metadata": {
        "id": "m5Nk2WW0Zs6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "AOQZoaY8adls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tn, fp, fn, tp = conf_mat_df.ravel()\n",
        "tp"
      ],
      "metadata": {
        "id": "DQ256v8maayd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}