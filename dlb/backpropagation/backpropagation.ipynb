{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68f30817",
   "metadata": {},
   "source": [
    "## Backpropagation example\n",
    "\n",
    "With this numerical example we illustrate how forward- and back-propagation work to learn the weights (parameters) of a **neural network**.\n",
    "\n",
    "We use a very simple network: this is far from a real-application network, but serves well the purpose of showing with numbers what happens in the network.\n",
    "\n",
    "In particular, the following simplifications apply:\n",
    "- only one training example (one record, with two features $x_1$ and $x_2$)\n",
    "- two numerical outputs $y = [y_1,y_2]$ (e.g. two continuous measurements on the same training example)\n",
    "- one hidden (intermediate) layer with two nodes\n",
    "- no bias terms\n",
    "\n",
    "<img src=\"simple_network.jpg\" alt=\"network\" style=\"width: 800px;\"/>\n",
    "\n",
    "We use the notation:\n",
    "- $z_{ij}$ to indicate the linear combination of inputs in layer $i$ and node $j$\n",
    "- $a_{ij}$ to indicate the activated linear combination $z$ in layer $i$ and node $j$\n",
    "- $\\hat{y}$ to indicate predicted values for the target variable $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9dce52",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Let's define the input and target variables and **initialize the weights** (give some initial random values to the parameters of the neural network model).\n",
    "As for hyperparameters, we set the learning rate $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54fe269",
   "metadata": {},
   "outputs": [],
   "source": [
    "## input vars\n",
    "x1 = 0.15\n",
    "x2 = 0.08\n",
    "\n",
    "## training outputs (two continuous measurements -e.g. phenotypes- on the same example)\n",
    "y1 = 0.05\n",
    "y2 = 0.95\n",
    "\n",
    "## initialization of model parameters\n",
    "w1 = 0.15\n",
    "w2 = 0.10\n",
    "w3 = 0.12\n",
    "w4 = 0.09\n",
    "w5 = 0.18\n",
    "w6 = 0.20\n",
    "w7 = 0.16\n",
    "w8 = 0.24\n",
    "\n",
    "## setting the hyperparameters\n",
    "alpha = 0.75 ## learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a1de4",
   "metadata": {},
   "source": [
    "### A little set-up\n",
    "\n",
    "We import some needed Python libraries and define functions that we'll use in this example:\n",
    "\n",
    "- **logistic (sigmoid) function**: used to activate the linear combinations ($z$'s) calculated in the intermediate and output layers\n",
    "- **mean squared error (MSE)**: cost function used to evaluate the performance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5656ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "## vectors\n",
    "y = np.array([y1,y2]) ## vector of training target variables\n",
    "\n",
    "## logistic function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "## cost function (mean squared error); the 1/2 is the normalization constant (2 outputs)\n",
    "def MSE(y,y_hat):\n",
    "    return sum((1/2)*(y-y_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf60c46",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "\n",
    "We start moving forward along the network: from inputs to outputs.\n",
    "First, we calculate the linear combinations of inputs $z$'s in the hidden layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd58823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_11 is:  0.0305\n",
      "z_12 is:  0.0252\n"
     ]
    }
   ],
   "source": [
    "z11 = w1*x1 + w2*x2\n",
    "z12 = w3*x1 + w4*x2\n",
    "\n",
    "print('z_11 is: ', z11)\n",
    "print('z_12 is: ', z12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be54f6d2",
   "metadata": {},
   "source": [
    "From the linear combinations $z$'s, we can now calculate the \"**activated**\" values $a$'s using the **sigmoid activation function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9422e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_11 is:  0.5076244089586275\n",
      "a_12 is:  0.5062996666251706\n"
     ]
    }
   ],
   "source": [
    "a11 = sigmoid(z11)\n",
    "a12 = sigmoid(z12)\n",
    "\n",
    "print('a_11 is: ', a11)\n",
    "print('a_12 is: ', a12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a0a5c",
   "metadata": {},
   "source": [
    "We now move to the next layer, the **output layer** and calculate the linear combination of the inputs (the activations from the previous -hidden- layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1a1285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_21 is:  0.19263232693758708\n",
      "z_22 is:  0.20273182542342133\n"
     ]
    }
   ],
   "source": [
    "z21 = w5*a11+w6*a12 ## linear combination from the first node in the output layer\n",
    "z22 = w7*a11+w8*a12 ## linear combination from the second node in the output layer\n",
    "\n",
    "print('z_21 is: ', z21)\n",
    "print('z_22 is: ', z22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc32651",
   "metadata": {},
   "source": [
    "We can now conclude the first forward propagation pass and calculate the predicted output values, using again the *sigmoid activation function*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330af3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two predicted outputs are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.54801; 0.55051'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat1 = sigmoid(z21)\n",
    "y_hat2 = sigmoid(z22)\n",
    "\n",
    "y_hat = np.array([y_hat1,y_hat2])\n",
    "\n",
    "print(\"The two predicted outputs are\")\n",
    "'; '.join([str(round(x,5)) for x in y_hat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1b123",
   "metadata": {},
   "source": [
    "### The cost\n",
    "\n",
    "With the predicted and actual target values we can calculate the cost, i.e. by how much we are currently off.\n",
    "Since in this simplified example we assumed that the target values are continuous variables, we can use **mean squared error** (*MSE*), a typical cost function for continuous variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea59df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two target outputs are\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.05; 0.95'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The two target outputs are\")\n",
    "'; '.join([str(round(x,5)) for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f4590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after the first forward propagation pass is:  0.20380293722737602\n"
     ]
    }
   ],
   "source": [
    "cost_1 = MSE(y,y_hat)\n",
    "\n",
    "print('The cost after the first forward propagation pass is: ', cost_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf933089",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "Finally, we can start moving backwards across the network: from the **cost** to the **coefficients**.\n",
    "\n",
    "Our goal with back propagation is to **update the weights** in the network so that they cause the network output to be closer the target output, thereby minimizing the error for each output neuron and the network as a whole.\n",
    "\n",
    "Let's start from the coefficient used to weigh the first input ($a_{11}$) in the linear combination $z_{21}$ calculated in the first node of the second (output) layer: $w_5$.\n",
    "\n",
    "We see from the figure below that we need to move backwards, from the cost, to the prediction $\\hat{y}_1$, to the lienar combination $z_{21}$. This is because $z_{21}$ is where the weight $w_5$ is indeed used:\n",
    "\n",
    "$$\n",
    "z_{21} = w_5 \\cdot a_{11} + w_6 \\cdot a_{12}\n",
    "$$\n",
    "\n",
    "Therefore: $\\text{MSE}(y,\\hat{y})$ $\\rightarrow$ $\\hat{y}_1$ $\\rightarrow$ $z_{21}$ $\\rightarrow$ $w_5$\n",
    "\n",
    "<img src=\"first_back_prop.jpg\" alt=\"first back propgation step\" style=\"width: 800px;\"/>\n",
    "\n",
    "This very first backpropagation step involves calculating the **derivative of the cost function** $MSE()$ with respect to the target coefficient $w_5$. Using the [chain rule](https://mathsathome.com/chain-rule-differentiation/), this can be expressed as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_5} = \\frac{\\partial MSE}{\\partial \\hat{y}_1} \\cdot \\frac{\\partial \\hat{y}_1}{\\partial z_{21}} \\cdot \\frac{\\partial z_{21}}{\\partial w_5}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f034af",
   "metadata": {},
   "source": [
    "#### The first link in the chain\n",
    "\n",
    "Let's start with the first element in the chain: $ \\frac{\\partial MSE}{\\partial \\hat{y}_1} $.\n",
    "The mean squared error (cost) is the normalised sum of the two prediction errors ($\\hat{y}_1$ and $\\hat{y}_2$):\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} (y_1-\\hat{y}_1)^2 + \\frac{1}{2}(y_2-\\hat{y}_2)^2\n",
    "$$\n",
    "\n",
    "since we are partialling on $\\hat{y}_1$ (our variable of interest), the second term in the sum is a **constant** $\\rightarrow$ the derivative of a constant is 0. We only need to take the derivative of the first term, of the form $f(x) = (a-x)^2$ $\\rightarrow$ $f'(x) = 2(a-x) \\cdot -1$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial \\hat{y}_1} = 2 \\cdot \\frac{1}{2} (y_1-\\hat{y}_1) \\cdot -1 + 0 = -(y_1-\\hat{y}_1)\n",
    "$$\n",
    "\n",
    "The $-1$ is because the variable in this partial derivative is $\\hat{y}_1$ (with coefficient -1):\n",
    "\n",
    "- $-1$: coefficient of -y_hat1 (function of function)\n",
    "- 0: derivative of a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337afa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first derivative in the chain:  0.49800971457469184\n"
     ]
    }
   ],
   "source": [
    "dMSEdy_hat1 = 2*(1/2)*(y1-y_hat1)*-1 + 0\n",
    "print('first derivative in the chain: ', dMSEdy_hat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aae23d",
   "metadata": {},
   "source": [
    "#### The second link in the chain\n",
    "\n",
    "Now we need to calculate the derivative of the prediction with respect to the linear corresponding combination, $\\frac{\\partial \\hat{y}_1}{ \\partial z_{21}}$. \n",
    "Let's remember that $\\hat{y}_1 = \\sigma(z_{21})$.\n",
    "\n",
    "The **derivative of the logistic (sigmoid) function** is: $\\sigma'(x) = \\sigma(x) \\cdot (1-sigma(x))$. \n",
    "In our case, this would be:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_1}{ \\partial z_{21}} = \\hat{y}_1 \\cdot (1 - \\hat{y}_1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6957ee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second derivative in the chain:  0.24769506730645663\n"
     ]
    }
   ],
   "source": [
    "dy_hat1dz21 = y_hat1*(1-y_hat1)\n",
    "print('second derivative in the chain: ', dy_hat1dz21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8327a0",
   "metadata": {},
   "source": [
    "#### The final link in the chain\n",
    "\n",
    "Now it's the turn for $\\frac{\\partial z_{21}}{\\partial w_5}$. This is the derviative of the linear combination $z_{21} = \\mathbf{w_5} \\cdot \\mathbf{a_{11}} + w_6 \\cdot a_{12}$, which is pretty simple: the coefficient of our variable of interest ($w_5$), i.e. $a_{11}$ (the remaining terms of the expression are constants, whose derivatives are zero).\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z_{21}}{\\partial w_5} = a_1 + 0 + 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c93b6656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "third derivative in the chain:  0.5076244089586275\n"
     ]
    }
   ],
   "source": [
    "dz21dw5 = a11\n",
    "print('third derivative in the chain: ', dz21dw5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc00fcf",
   "metadata": {},
   "source": [
    "#### Applying the chain rule\n",
    "\n",
    "We now have all the elements to calculate the product in the chain:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_5} = \\frac{\\partial MSE}{\\partial \\hat{y}_1} \\cdot \\frac{\\partial \\hat{y}_1}{\\partial z_{21}} \\cdot \\frac{\\partial z_{21}}{\\partial w_5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13a2b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The derivative of the cost function with respect to w5 is:  0.06261778041978408\n"
     ]
    }
   ],
   "source": [
    "dMSEdw5 = dMSEdy_hat1*dy_hat1dz21*dz21dw5\n",
    "print('The derivative of the cost function with respect to w5 is: ', dMSEdw5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7ee02",
   "metadata": {},
   "source": [
    "### The updating step\n",
    "\n",
    "With the derivative of the cost function with respect to the coefficient $w_5$, we can now proceed to the updating of the coefficient (**the \"learning\"**):\n",
    "\n",
    "$$\n",
    "w_5+ = w_5 - \\alpha \\cdot \\frac{\\partial MSE}{\\partial w_5}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1fd51a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated w5 coefficient WILL be:  0.13303666468516193\n"
     ]
    }
   ],
   "source": [
    "w5upd = w5-alpha*dMSEdw5\n",
    "print('The updated w5 coefficient WILL be: ', w5upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165bcd54",
   "metadata": {},
   "source": [
    "**IMPORTANT**: we are saving the updated coefficient to a new variable (`w5upd`) instead of directly updating the coefficient variable (`w5`) because the backpropagation algorithm performs the updating simultaneously once all derviatives have been calculated. Therefore, for the calculation of all the derivatives in the network (the 'backpropagation pass'), the 'old' coefficients (from the previous step) are used. That's why we say \"the updated coefficient WILL BE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac69dd0",
   "metadata": {},
   "source": [
    "### Apply backpropagation to all coefficients in the output layer\n",
    "\n",
    "We can now apply the same logic to calculate the partial derivatives for the coefficients $w_6$, $w_7$, $w_8$.\n",
    "\n",
    "For $w_6$, we need to calculate:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_6} = \\frac{\\partial MSE}{\\partial \\hat{y}_1} \\cdot \\frac{\\partial \\hat{y}_1}{\\partial z_{21}} \\cdot \\frac{\\partial z_{21}}{\\partial w_6}\n",
    "$$\n",
    "\n",
    "The first two terms (\"links\") in the chain have already been calculated for $w_5$; we therefore need to calculate only the extra term $\\frac{\\partial z_{21}}{\\partial w_6}$, which again is the relevant coefficient of the linear combination ($a_{12}$, in this case): $z_{21} = w_5 \\cdot a_{11} + \\mathbf{w_6} \\cdot \\mathbf{a_{12}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6060c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated w6 coefficient WILL be:  0.15315922443074143\n"
     ]
    }
   ],
   "source": [
    "## w6\n",
    "dMSEdy_hat1    ## 1) already calculated for w5\n",
    "dy_hat1dz21    ## 2) already calculated for w5\n",
    "dz21dw6 = a12  ## 3)\n",
    "\n",
    "dMSEdw6 = dMSEdy_hat1*dy_hat1dz21*dz21dw6\n",
    "w6upd = w6-alpha*dMSEdw6\n",
    "\n",
    "print('The updated w6 coefficient WILL be: ', w6upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cce24ab",
   "metadata": {},
   "source": [
    "For $w_7$ we need to do similar calculations, since we are now in the second node of the second (output) layer ($u_{22}$, $u$ per unit), and the terms are now:\n",
    "\n",
    "- $\\hat{y}_2$: the second prediction\n",
    "- $z_{22}$: the lienar combination in $u_{22}$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_7} = \\frac{\\partial MSE}{\\partial \\hat{y}_2} \\cdot \\frac{\\partial \\hat{y}_2}{\\partial z_{22}} \\cdot \\frac{\\partial z_{22}}{\\partial w_7}\n",
    "$$\n",
    "\n",
    "- $\\frac{\\partial MSE}{\\partial \\hat{y}_2} = 2 \\cdot \\frac{1}{2} (y_2 - \\hat{y}_2) \\cdot -1$\n",
    "- $\\frac{\\partial \\hat{y}_2}{\\partial z_{22}} = \\hat{y}_2 \\cdot (1 - \\hat{y}_2)$ \n",
    "- $z_{22} = \\mathbf{w_7} \\cdot \\mathbf{a_{11}} + w_8 \\cdot a_{12}$ $\\rightarrow$ $\\frac{\\partial z_{22}}{\\partial w_7} = a_{11}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938d26b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated w7 coefficient WILL be:  0.19763525145838332\n"
     ]
    }
   ],
   "source": [
    "## w7\n",
    "dMSEdy_hat2 = 0 + 2*(1/2)*(y2-y_hat2)*-1 ## 1)\n",
    "dy_hat2dz22 = y_hat2*(1-y_hat2)          ## 2)\n",
    "dz22dw7 = a11                            ## 3)\n",
    "\n",
    "dMSEdw7 = dMSEdy_hat2*dy_hat2dz22*dz22dw7\n",
    "w7upd = w7-alpha*dMSEdw7\n",
    "\n",
    "print('The updated w7 coefficient WILL be: ', w7upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f1f08",
   "metadata": {},
   "source": [
    "Just like with $w_6$, for $w_8$ the first two terms (\"links\") in the chain have already been calculated (for $w_7$ in this case) and therefore need to calculate only the extra term $\\frac{\\partial z_{22}}{\\partial w_7}$, which again is the relevant coefficient of the linear combination ($a_{12}$, in this case): $z_{22} = w_7 \\cdot a_{11} + \\mathbf{w_8} \\cdot \\mathbf{a_{12}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971bdcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated w8 coefficient WILL be:  0.27753703511977285\n"
     ]
    }
   ],
   "source": [
    "## w8\n",
    "dMSEdy_hat2   ## 1) already calculated for w7\n",
    "dy_hat2dz22   ## 2) already calculated for w7\n",
    "dz22dw8 = a12 ## 3)\n",
    "\n",
    "dMSEdw8 = dMSEdy_hat2*dy_hat2dz22*dz22dw8\n",
    "w8upd = w8-alpha*dMSEdw8\n",
    "\n",
    "print('The updated w8 coefficient WILL be: ', w8upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4670a88",
   "metadata": {},
   "source": [
    "### The hidden (intermediate) layer\n",
    "\n",
    "Let's move backward in the network: after the output layer, we now engage in our battle with the intermediate layer.\n",
    "\n",
    "We take as starting point the coefficient used in the linear combination in $u_{11}$ (first node of the first -hidden- layer) for the first input variable $x_1$ (namely, $\\mathbf{w_1}$). \n",
    "As from the black arrows in the figure below, we need to calculate the derivative of the cost function with respect to $w_1$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial w_1} = \\frac{\\partial \\text{MSE}}{\\partial a_{11}} \\cdot \\frac{\\partial a_{11}}{\\partial z_{11}} \\cdot \\frac{\\partial z_{11}}{\\partial w_1}\n",
    "$$\n",
    "\n",
    "Again, the **chain rule**!\n",
    "\n",
    "<img src=\"backprop_hidden_layer.jpg\" alt=\"network\" style=\"width: 800px;\"/>\n",
    "\n",
    "#### The first link in the new chain\n",
    "\n",
    "One important difference with the output layer, hinges on the connections between layers: as a matter of fact, the output of the intermediate nodes ($a_{11}$, $a_{12}$) influences both final outputs ($\\hat{y}_1$ through $z_{21}$; $\\hat{y}_2$ through $z_{22}$). \n",
    "Therefore we have to consider both paths: \n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\text{MSE}_1 + \\text{MSE}_2 \\rightarrow \\frac{\\partial \\text{MSE}}{\\partial a_{11}} = \\frac{\\partial \\text{MSE}_1}{\\partial a_{11}} + \\frac{\\partial \\text{MSE}_2}{\\partial a_{11}}\n",
    "$$\n",
    "\n",
    "\n",
    "**Multiple chains** are involved here: i) first, $\\frac{\\partial \\text{MSE}_1}{\\partial a_{11}}$, which reflects the chain MSE $\\rightarrow$ $\\hat{y}_1$ $\\rightarrow$ $z_{21}$ $\\rightarrow$ $a_{11}$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}_1}{\\partial a_{11}} = \\frac{\\partial \\text{MSE}_1}{\\partial \\hat{y}_1} \\cdot \\frac{\\partial \\hat{y}_1}{\\partial z_{21}} \\cdot \\frac{\\partial z_{21}}{\\partial a_{11}}\n",
    "$$\n",
    "\n",
    "1. $\\frac{\\partial \\text{MSE}_1}{\\partial \\hat{y}_1} = -(y_1-\\hat{y}_1)$\n",
    "2. $\\frac{\\partial \\hat{y}_1}{\\partial z_{21}} = \\hat{y}_1 \\cdot (1-\\hat{y}_1)$\n",
    "3. $z_{21} = w_5a_{11} + w_6a_{12}$ $\\rightarrow$ $\\frac{\\partial z_{21}}{\\partial a_{11}}=w_5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a03de82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of the cost for the first predictions with respect to the input a11:  0.022203818958752557\n"
     ]
    }
   ],
   "source": [
    "dMSEdy_hat1 ## 1) already calculated for w5\n",
    "dy_hat1dz21 ## 2) already calculated for w5\n",
    "dz21da11 = w5\n",
    "\n",
    "dMSE1da11 = dMSEdy_hat1*dy_hat1dz21*dz21da11\n",
    "print('Derivative of the cost for the first predictions with respect to the input a11: ', dMSE1da11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ae7ff",
   "metadata": {},
   "source": [
    "ii) similarly, for the derivative of the error for the second prediction with respect to the same input (activation $a_{11}$). The chain now is MSE $\\rightarrow$ $\\hat{y}_2$ $\\rightarrow$ $z_{22}$ $\\rightarrow$ $a_{11}$, which translates to the derivativers below:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}_2}{\\partial a_{11}} = \\frac{\\partial \\text{MSE}_2}{\\partial \\hat{y}_2} \\cdot \\frac{\\partial \\hat{y}_2}{\\partial z_{22}} \\cdot \\frac{\\partial z_{22}}{\\partial a_{11}}\n",
    "$$\n",
    "\n",
    "1. $\\frac{\\partial \\text{MSE}_2}{\\partial \\hat{y}_2} = -(y_2-\\hat{y}_2)$\n",
    "2. $\\frac{\\partial \\hat{y}_2}{\\partial z_{22}} = \\hat{y}_2 \\cdot (1-\\hat{y}_2)$\n",
    "3. $z_{22} = w_7a_{11} + w_8a_{12}$ $\\rightarrow$ $\\frac{\\partial z_{22}}{\\partial a_{11}}=w_7$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "863b0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of the cost for the first predictions with respect to the input a11:  -0.015816523994435183\n"
     ]
    }
   ],
   "source": [
    "dMSEdy_hat2 ## 1) already calculated for w7\n",
    "dy_hat2dz22 ## 2) already calculated for w7\n",
    "dz22da11 = w7\n",
    "\n",
    "dMSE2da11 = dMSEdy_hat2*dy_hat2dz22*dz22da11\n",
    "print('Derivative of the cost for the first predictions with respect to the input a11: ', dMSE2da11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b909b1",
   "metadata": {},
   "source": [
    "And we put together the two paths to the cost:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial a_{11}} = \\frac{\\partial \\text{MSE}_1}{\\partial a_{11}} + \\frac{\\partial \\text{MSE}_2}{\\partial a_{11}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83da1926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of the total cost with respect to the input a11:  0.006387294964317374\n"
     ]
    }
   ],
   "source": [
    "dMSEda11 = dMSE1da11 + dMSE2da11\n",
    "print('Derivative of the total cost with respect to the input a11: ', dMSEda11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd34dc7",
   "metadata": {},
   "source": [
    "#### The second link in the new chain\n",
    "\n",
    "Here we need to remember that activation $a_{11} = \\sigma(z_{11})$ is the output of the **sigmoid function**, hence:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial a_{11}}{\\partial z_{11}} = a_{11} \\cdot (1 - a_{11})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d9db91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of the activation a11 with respect to the linear combination z11:  0.2499418683880316\n"
     ]
    }
   ],
   "source": [
    "da11dz11 = a11*(1-a11)\n",
    "print('Derivative of the activation a11 with respect to the linear combination z11: ', da11dz11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3fbfa",
   "metadata": {},
   "source": [
    "#### The third (and final) link in the new chain\n",
    "\n",
    "For this, we just need to remember that $z_{11} = \\mathbf{w1x1} + w2x2$, hence:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z_{11}}{\\partial w_1} = x_1\n",
    "$$\n",
    "\n",
    "The derivative of the linear combination $z_{11}$ with respect to the coefficient $w_1$ (our current objective!) is equal to the first input variable $x_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7e8f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of the linear combination z11 with respect to weight w1:  0.15\n"
     ]
    }
   ],
   "source": [
    "dz11dw1 = x1\n",
    "print('Derivative of the linear combination z11 with respect to weight w1: ', dz11dw1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc96296",
   "metadata": {},
   "source": [
    "#### Applying the chain rule\n",
    "\n",
    "We now have all the elements to calculate the product in the new chain:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial w_1} = \\frac{\\partial \\text{MSE}}{\\partial a_{11}} \\cdot \\frac{\\partial a_{11}}{\\partial z_{11}} \\cdot \\frac{\\partial z_{11}}{\\partial w_1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eeb93b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative of the cost function with respect to weight w1:  0.0002394678655990425\n"
     ]
    }
   ],
   "source": [
    "dMSEdw1 = dMSEda11*da11dz11*dz11dw1\n",
    "print('Derivative of the cost function with respect to weight w1: ', dMSEdw1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10415ab",
   "metadata": {},
   "source": [
    "### The updating step\n",
    "\n",
    "With the derivative of the cost function with respect to the coefficient $w_1$, we can now proceed to the updating of the coefficient (**the \"learning\"**):\n",
    "\n",
    "$$\n",
    "w_1+ = w_1 - \\alpha \\cdot \\frac{\\partial \\text{MSE}}{\\partial w_1}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ae5d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated w1 coefficient WILL be:  0.14982039910080072\n"
     ]
    }
   ],
   "source": [
    "w1upd = w1-alpha*dMSEdw1\n",
    "print('The updated w1 coefficient WILL be: ', w1upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c8efb",
   "metadata": {},
   "source": [
    "### First epoch is completed!\n",
    "\n",
    "All these pretty complicated calculations (from an ultra-simplified example!) in the forward- and back-propagation passes, represent **one epoch**!  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
