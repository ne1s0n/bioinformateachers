{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16f2f29e",
      "metadata": {
        "id": "16f2f29e"
      },
      "source": [
        "# One-layer neural network model for softmax regression (multiclass classification)\n",
        "\n",
        "In this notebook, we extend logistic regression to multiclass classification using [softmax regression](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression) with.\n",
        "neural network implementation with one single layer (**softmax layer**).\n",
        "This is equivalent to a multinomial logistic regression model, only it is solved using neural networks (forward and backpropagation) rather than with maximum likelihood (or similar algorithms).\n",
        "\n",
        "As example data, we again use Fisher's [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6deb0024",
      "metadata": {
        "id": "6deb0024"
      },
      "source": [
        "Basically, a neural network implementation of softmax regression looks like graph below.\n",
        "There are as many units as classes in the multiclass classification problems (e.g. three classes in the *Iris* dataset: *Iris setos*, *Iris versicolor*, *Iris virginica*): each unit receives the vector of input features $\\mathbf{x}$ and multiplies it by a vector of weights $\\mathbf{w_u}$, specific to each unit $u$. The results are summed up together and the unit bias term $b_u$ is added. The real-valued $z_u$ variable is then activated with the *softmax* activation function to give the probability of belonging to the various classes of the problem.\n",
        "In other words, each unit performs a specific and independent linear combination of the input variables, and the outputs the probability of belonging to one class: i.e., each unit models the probability of one class given the data (e.g. $P(y=\\text{iris setosa}|x)$).\n",
        "\n",
        "<img src=\"softmax_layer.png\" alt=\"perceptron\" style=\"height: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries and setting the random seed\n",
        "\n",
        "First of all, we load some necessary libraries; then we setup the random seed to ensure reproducibility of results. Since tensorflow uses an internal random generator we need to fix both the general seed (via numpy `seed()`) and tensorflow seed (via `set_seet()`)"
      ],
      "metadata": {
        "id": "5Z63YlH0OgfH"
      },
      "id": "5Z63YlH0OgfH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e86c1bf",
      "metadata": {
        "id": "9e86c1bf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "  # Set the seed using keras.utils.set_random_seed. This will set:\n",
        "  # 1) `numpy` seed\n",
        "  # 2) `tensorflow` random seed\n",
        "  # 3) `python` random seed\n",
        "tf.keras.utils.set_random_seed(121)\n",
        "\n",
        "  # This will make TensorFlow ops as deterministic as possible, but it will\n",
        "  # affect the overall performance, so it's not enabled by default.\n",
        "  # `enable_op_determinism()` is introduced in TensorFlow 2.9.\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "From `sklearn.datasets` we get a \"bunch\" object that contains both the `target` and the `features` (to be accessed as attributes): `<dataset>.target` and `<dataset>.data`."
      ],
      "metadata": {
        "id": "zZ3vzxq4B0IQ"
      },
      "id": "zZ3vzxq4B0IQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09318d92",
      "metadata": {
        "id": "09318d92"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "\n",
        "## 1)\n",
        "iris = sklearn.datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we convert data and features (originally as `numpy` arrays) to `pandas` dataframes / series"
      ],
      "metadata": {
        "id": "1rStMQUKDmt-"
      },
      "id": "1rStMQUKDmt-"
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data = pd.DataFrame(features, columns=iris.feature_names) #converting numpy array -> pandas DataFrame\n",
        "iris.target = pd.Series(target) #converting numpy array -> pandas Series"
      ],
      "metadata": {
        "id": "6jEcpPgtDDYh"
      },
      "id": "6jEcpPgtDDYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **iris** dataset is a historic dataset first used by **Ronald Fisher** in his 1936 paper on linear discriminant analysis (LDA).\n",
        "The dataset contains information on 150 flower samples, belonging to three species of Iris (Iris setosa, Iris virginica and Iris versicolor: the `target`).\n",
        "Four `features` were measured from each sample: the length and the width of the sepals and of the petals, in centimeters."
      ],
      "metadata": {
        "id": "Bpq4XO6UI_ta"
      },
      "id": "Bpq4XO6UI_ta"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "As said, the feature data has 150 rown and 4 columns:"
      ],
      "metadata": {
        "id": "FQp5ITO0KXKF"
      },
      "id": "FQp5ITO0KXKF"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of the feature table: ' + str(iris.data.shape))"
      ],
      "metadata": {
        "id": "BaEeW57GKZ9E"
      },
      "id": "BaEeW57GKZ9E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes are represented via a numeric index: 0 for *setosa*, 1 for *versicolor*, 2 for *virginica*. The samples are in order: the first 50 samples are *setosa*, then 50 *versicolor* and the last 50 are *virginica*.\n",
        "\n",
        "When working with a new dataset, it is always importat to plot the data. We are unfortunately talking about a 5-dimensional dataset (the four features + the target class) which is not easily representable.\n",
        "One possibility is to take a slice (a subset) of the whole dataset.\n",
        "\n",
        "In the next code chunk we plot two features plus the class."
      ],
      "metadata": {
        "id": "OBMUK3_NL5bI"
      },
      "id": "OBMUK3_NL5bI"
    },
    {
      "cell_type": "code",
      "source": [
        "## SELECT FEATURES TO PLOT\n",
        "#change these two values to plot different features, remembering the numbering:\n",
        "# 0 : sepal length (cm)\n",
        "# 1 : sepal width (cm)\n",
        "# 2 : petal length (cm)\n",
        "# 3 : petal width (cm)\n",
        "feature_x = 0\n",
        "feature_y = 1\n",
        "\n",
        "#starting a new plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "#adding data in three bunches of 50, once per class\n",
        "ax.scatter(x=iris.data.iloc[0:50,feature_x],    y=iris.data.iloc[0:50,feature_y],    c='red',   label=iris.target_names[0])\n",
        "ax.scatter(x=iris.data.iloc[50:100,feature_x],  y=iris.data.iloc[50:100,feature_y],  c='green', label=iris.target_names[1])\n",
        "ax.scatter(x=iris.data.iloc[100:150,feature_x], y=iris.data.iloc[100:150,feature_y], c='blue',  label=iris.target_names[2])\n",
        "\n",
        "#the axis names are taken from feature names\n",
        "ax.set_xlabel(iris.feature_names[feature_x])\n",
        "ax.set_ylabel(iris.feature_names[feature_y])\n",
        "\n",
        "#adding the legend and printing the plot\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KrqLvYQWNav_"
      },
      "id": "KrqLvYQWNav_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, we are going to use all three classes as they are."
      ],
      "metadata": {
        "id": "PawFSrXlNwe_"
      },
      "id": "PawFSrXlNwe_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem is that our target array `iris.target` is a numeric array (e.g. [1 0 0 2 1 1 0 ...]).\n",
        "However teose numbers (0, 1, and 2) do not represent real values. In other words, \"virginica\" is not twice \"versicolor\". Numbers here are used as labels, not as quantities.\n",
        "\n",
        "As a matter of fact, to properly train a model the structure of the target array must be changed to [one-hot encoding](https://en.wikipedia.org/wiki/One-hot). In simple terms, it needs to become a table with one row per sample (150 in total) and one column per class (three in total). Something like:\n",
        "\n",
        "| Setosa | Versicolor | Virginica |\n",
        "|------|------|------|\n",
        "|   0  |   1  |   0  |\n",
        "|   1  |   0  |   0  |\n",
        "|   1  |   0  |   0  |\n",
        "|   0  |   0  |   1  |\n",
        "\n",
        "As you can see the first sample is Versicolor, the second and third are Setosa, the last one is Virginica. Note that there is only a single \"one\" per row.\n",
        "\n",
        "We need to do a little **preprocessing**."
      ],
      "metadata": {
        "id": "7gRqeggVWVW1"
      },
      "id": "7gRqeggVWVW1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "As said, we need to convert a numeric vector to a one-hot encoding (OHE) representation.\n",
        "Luckily, it's easy to pass to one-hot encode using the keras function [to_categorical](https://keras.io/api/utils/python_utils/#to_categorical-function):\n",
        "\n",
        "To make the problem a little more challenging (and interesting) we decide to **drop half of the features**, **using only the first two** columns."
      ],
      "metadata": {
        "id": "zD4xK76sOajn"
      },
      "id": "zD4xK76sOajn"
    },
    {
      "cell_type": "code",
      "source": [
        "#the \"utils\" subpackage is very useful, take a look to it when you have time\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#converting to categorical\n",
        "target_multi_cat = tf.keras.utils.to_categorical(target)\n",
        "\n",
        "#since everything else is a Pandas dataframe, let's stick to the format\n",
        "#for consistency\n",
        "target_multi_cat = pd.DataFrame(target_multi_cat)\n",
        "\n",
        "#let's take a look\n",
        "print(target_multi_cat)"
      ],
      "metadata": {
        "id": "SfSXs5pZOaDO"
      },
      "id": "SfSXs5pZOaDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the first two features, to make the example comparable with the previous notebook on binary classification"
      ],
      "metadata": {
        "id": "vBM2GqsHZrK4"
      },
      "id": "vBM2GqsHZrK4"
    },
    {
      "cell_type": "code",
      "source": [
        "features = iris.data.iloc[:,0:2] ## we are selecting the first two features / columns"
      ],
      "metadata": {
        "id": "htJv49_hSXN6"
      },
      "id": "htJv49_hSXN6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation sets\n",
        "\n",
        "Each time there is some kind of \"learning\" involved we need to split our data. A subset will be used for training, and a subset will be used for validation.\n",
        "\n",
        "In our current dataset the samples are sorted by class: the first 100 are \"non-virginica\" and the remaining 50 are \"virginica\".\n",
        "We want to keep this 2:1 proportion (roughly) the same in both train and validation set.\n",
        "\n",
        "Obviously (given the ordered data), taking the first $80\\%$ (120 samples) of the data as training and the rest (30 samples) as validation would be a bad choice ... (only 'virginica' samples in the validation set, 4:1 class proportion in the training set).   \n",
        "\n",
        "Simple random sampling would also not be a good solution, since the 2:1 proportion will not be maintained.\n",
        "\n",
        "Therefore we are going to use what is called a [stratified approach](https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/) using a [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) object from `scikit-learn`:\n"
      ],
      "metadata": {
        "id": "K98ZAN9-S4a8"
      },
      "id": "K98ZAN9-S4a8"
    },
    {
      "cell_type": "code",
      "source": [
        "#we want to have the same proportion of classes in both train and validation sets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "test_pct = 0.2\n",
        "\n",
        "#building a StratifiedShuffleSplit object (sss among friends) with 20% data\n",
        "#assigned to validation set (here called \"test\")\n",
        "#random_state is used to control class balance between training and test sets (None to switch to random behavior)\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size= test_pct, random_state=0)\n",
        "\n",
        "for train_index, val_index in sss.split(features, target_multi_cat):\n",
        "    features_train = features.iloc[train_index, :]\n",
        "    features_val   = features.iloc[val_index, :]\n",
        "    target_train   = target_multi_cat.iloc[train_index, :]\n",
        "    target_val     = target_multi_cat.iloc[val_index, :]"
      ],
      "metadata": {
        "id": "Zz1Miz6TSw84"
      },
      "id": "Zz1Miz6TSw84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now perform a little sanity check to see whether the split worked as expected:"
      ],
      "metadata": {
        "id": "64LzrQSSalv9"
      },
      "id": "64LzrQSSalv9"
    },
    {
      "cell_type": "code",
      "source": [
        "#shapes\n",
        "print(features_train.shape)\n",
        "print(features_val.shape)\n",
        "print(target_train.shape)\n",
        "print(target_val.shape)\n",
        "\n",
        "#number of classes per split\n",
        "print('\\nClasses in train set:')\n",
        "print(target_train.sum())\n",
        "print('\\nClasses in validation set:')\n",
        "print(target_val.sum())"
      ],
      "metadata": {
        "id": "IAMFHDFIVD1L"
      },
      "id": "IAMFHDFIVD1L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have now a balanced dataset, with 40 instances for each class in the training set and 10 in the validation set. Job done!"
      ],
      "metadata": {
        "id": "mki_AVWuVGjh"
      },
      "id": "mki_AVWuVGjh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature normalization\n",
        "\n",
        "We calculate the average and standard deviation on the training data: then we use these values to normalize the features both in the training and in the test datasets <!-- (!! **IMPORTANT** !!) -->"
      ],
      "metadata": {
        "id": "FULjbTrWlKv7"
      },
      "id": "FULjbTrWlKv7"
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating features averages and std devs\n",
        "avg = features_train.mean()\n",
        "std = features_train.std()\n",
        "\n",
        "#standardizing the data (mean 0, std 1)\n",
        "features_train = (features_train - avg)/std\n",
        "features_val = (features_val - avg)/std"
      ],
      "metadata": {
        "id": "QmEsMng2lOLL"
      },
      "id": "QmEsMng2lOLL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the neural network model\n",
        "\n",
        "We want to use a neural network model for softmax regression.\n",
        "As for the rest of the book, in this notenook we are using the `Python`-based `Keras`/`Tensorflow` framework.\n",
        "\n",
        "Our neural network will be very minimal, as illustrated in the sketch at the beginning of this notebook: it will comprise only one layer (softmax layer) with three units (since this is a three-class problem) that will perform both 1) the linear combination of weighted input variables + bias term; and 2) softmax activation of the result from step 1, to produce the probabilities for a sample of belonging to each class.\n",
        "\n",
        "We are now ready to build the NN (neural network) model!\n",
        "\n",
        "- model set-up\n",
        "- model architecture and compiling"
      ],
      "metadata": {
        "id": "ecoydX0bVgMx"
      },
      "id": "ecoydX0bVgMx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model set-up\n",
        "\n",
        "We first need to define some hyperparameters:\n",
        "\n",
        "1. number of classes (units in the softmax layer)\n",
        "2. activation function (`softmax`, this is a multiclass classification problem)\n",
        "3. optimizer (the algorithm that carries out forward and backpropagation to solve the model)\n",
        "4. the loss function (`categorical cross-entropy`, again this is multiclass classification!)"
      ],
      "metadata": {
        "id": "JHec8oN7cxvy"
      },
      "id": "JHec8oN7cxvy"
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3\n",
        "input_shape = features_train.shape[1]\n",
        "activation_function = 'softmax'\n",
        "optimising_method = 'adam'\n",
        "loss_function = 'categorical_crossentropy'\n",
        "num_epochs = 200"
      ],
      "metadata": {
        "id": "_mPrv77YVSwo"
      },
      "id": "_mPrv77YVSwo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture\n",
        "\n",
        "This is a one-layer one-unit neural network model.\n",
        "The neural network is fully connected, meaning that the unit receives in input all features."
      ],
      "metadata": {
        "id": "HAbTw4oDdSMS"
      },
      "id": "HAbTw4oDdSMS"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# 3-class softmax regression in Keras\n",
        "model_multi = Sequential()\n",
        "model_multi.add(Dense(units = num_classes, activation=activation_function, input_dim=input_shape))\n",
        "\n",
        "#compile the model specifying the new multiclass loss\n",
        "model_multi.compile(optimizer=optimising_method, loss=loss_function)"
      ],
      "metadata": {
        "id": "LlgkOZuudTvT"
      },
      "id": "LlgkOZuudTvT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the `.summary()` method we can take a look \"under the hood\":"
      ],
      "metadata": {
        "id": "Awoe08PBd_HG"
      },
      "id": "Awoe08PBd_HG"
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_multi.summary())"
      ],
      "metadata": {
        "id": "NKOLG-tWd6o5"
      },
      "id": "NKOLG-tWd6o5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have to train 9 parameters: 3 coefficients (W1, W2 B) times three units/nodes.\n",
        "The output is a vector of length three (three probabilities normalised to sum to one). Excellent!"
      ],
      "metadata": {
        "id": "LQlHhEv7eHrC"
      },
      "id": "LQlHhEv7eHrC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the neural network model\n",
        "\n",
        "Now that the model has been built and compiled, we are ready to train it on the data.\n",
        "Training is an iterative process that cycles many times through what are called `epochs`. Remeber: one epoch is one cycle of forward and backward propagation.\n",
        "\n",
        "We'll go directly to the total number of epochs:"
      ],
      "metadata": {
        "id": "bMoZEu_phn7j"
      },
      "id": "bMoZEu_phn7j"
    },
    {
      "cell_type": "code",
      "source": [
        "history_multi = model_multi.fit(features_train, target_train, epochs=num_epochs, validation_data=(features_val, target_val), verbose=0)"
      ],
      "metadata": {
        "id": "OzRyL84ud7El"
      },
      "id": "OzRyL84ud7El",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We asked for ten epochs and the network did just that. At each iteration the network is trying really hard to minimize the [\"loss\"](https://keras.io/api/losses/). The specifics are defined by our choice of loss function (we selected `binary_crossentropy`). The basic idea is that the smaller the loss the better the fit.\n",
        "\n",
        "Note that the network minimizes the loss on the training set and does not use the validation set during the learning process. It can however measure the loss on the validation set to give us an idea on how well it can generalize on new data.\n",
        "\n",
        "It's handy at this point to define a function that takes in the `history` object returned by `.fit()` and plots it:"
      ],
      "metadata": {
        "id": "5gbvbxc6jmqa"
      },
      "id": "5gbvbxc6jmqa"
    },
    {
      "cell_type": "code",
      "source": [
        "#function to take a look at losses evolution\n",
        "def plot_loss_history(h, title):\n",
        "    plt.plot(h.history['loss'], label = \"Train loss\")\n",
        "    plt.plot(h.history['val_loss'], label = \"Validation loss\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "siu0zjjehvFf"
      },
      "id": "siu0zjjehvFf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_history(history_multi, 'Softmax multiclass ({} epochs)'.format(num_epochs))"
      ],
      "metadata": {
        "id": "K7SHMHUAnmFA"
      },
      "id": "K7SHMHUAnmFA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks promising. There's the clear same pattern we saw with logistic regression, with a strong improvement in the first hundred epochs (and then things become slow...)"
      ],
      "metadata": {
        "id": "nwdeKHYpj4X_"
      },
      "id": "nwdeKHYpj4X_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation\n",
        "\n",
        "As said, a model is useful to predict new, unknown data, and it is therefore critical to evaluate it's performance.\n",
        "\n",
        "Again, we look at the following:\n",
        "\n",
        "- decision boundary\n",
        "- confusion matrix / accuracy\n",
        "- Cohen's kappa"
      ],
      "metadata": {
        "id": "brqzSW3wlmOp"
      },
      "id": "brqzSW3wlmOp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Boundary\n",
        "\n",
        "We now need to extend the code for inspecting the decision boundary beyond the case of two classes.\n",
        "Unfortunately, the `plot_decision_regions` function from [mlxtend](http://rasbt.github.io/mlxtend/) module does not support one-hot encoded multiclasses natively.\n",
        "Luckily [there's a quick workaround](https://www.machinecurve.com/index.php/2019/10/17/how-to-use-categorical-multiclass-hinge-with-keras/#visualizing-the-decision-boundary), but if you get lost in the code don't worry and just look at the plot :)"
      ],
      "metadata": {
        "id": "Q1tXDHkGmR13"
      },
      "id": "Q1tXDHkGmR13"
    },
    {
      "cell_type": "code",
      "source": [
        "#we define a class to take the Keras model and convert its predictions\n",
        "#from \"one probability per iris type\" to \"just the iris type with the highest probability\"\n",
        "class Onehot2Int(object):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.model.predict(X)\n",
        "        return np.argmax(y_pred, axis=1)\n",
        "\n",
        "#we wrap our trained model, instantiating a new object\n",
        "keras_model_no_ohe = Onehot2Int(model_multi)"
      ],
      "metadata": {
        "id": "kdfsi_Uvk9IO"
      },
      "id": "kdfsi_Uvk9IO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#and we can now plot the decision boundary safely (we still need to convert\n",
        "#the target one-hot-encoded matrix to int, though)\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "plot_decision_regions(features_val.to_numpy(), np.argmax(target_val.to_numpy(), axis=1),\n",
        "                      clf=keras_model_no_ohe) ## clf = classifier object\n",
        "plt.title('Decision boundary for 0 (setosa) vs 1 (versicolor) vs 2 (virginica)')\n",
        "plt.xlabel(iris.feature_names[feature_x])\n",
        "plt.ylabel(iris.feature_names[feature_y])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vpoxza6DnNbP"
      },
      "id": "Vpoxza6DnNbP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The colored areas (orange, blue, green) represent the behaviour of the trained model; the blue squares, orange triangles and green circles are the actual samples in the validation set.\n",
        "\n",
        "The **decision boundaries are linear**, as expected by softmax regression. This means that all samples in the orange area will be classified as 1 (versicolor), all points in the blue area as 0 (setosa), and alls samples in the green area as 2 (virginica).\n",
        "\n",
        "Note that: i) it is very easy to classify correctly the *setosa* samples; ii) contrariwise, there are relatively many virginica samples in the yellow area (versicolor) and versicolor samples in the green area (virginica). The classes \"1\" and \"2\" are more difficult to distinguish based on the input features.\n",
        "\n",
        "Also note that, roughly speaking, the softmax regressor assigned approximately the same area to all three classes. This is a direct consequence of having a balanced dataset: each class comprises one thirds of the samples."
      ],
      "metadata": {
        "id": "F7ZHPR7BnYNY"
      },
      "id": "F7ZHPR7BnYNY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix / accuracy\n",
        "\n",
        "To construct the confusion matrix and to calculate the accuracy of the trained neural network model for softmax regression, we first need to get the predictions made on the validation set.\n",
        "Luckily, it's very easy to apply a trained model to new data (the validation set) via the [predict() method](https://keras.io/api/models/model_training_apis/#predict-method).\n",
        "\n",
        "We can thus get our prediction for the iris flowers (see below): note that we have now a vector of probabilities (three probabilities) for each sample in the validation set.\n",
        "Each sample will be classified based on the largest probability value (e.g. the first sample will be classified as \"2\", the secinda sample as \"1\" etc.)."
      ],
      "metadata": {
        "id": "1tXXdV6m4pnK"
      },
      "id": "1tXXdV6m4pnK"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model_multi.predict(features_val)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "Lzvgmz1noEbF"
      },
      "id": "Lzvgmz1noEbF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the predictions and the target labels in the validation set we can construct the **confusion matrix** and get a detailed overview of the model performance.  "
      ],
      "metadata": {
        "id": "33qkJTkEu35v"
      },
      "id": "33qkJTkEu35v"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predicted_classes = np.argmax(predictions,axis=1)\n",
        "predicted_classes = predicted_classes.reshape(len(predicted_classes),1)\n",
        "\n",
        "target_classes = iris.target.iloc[val_index].to_numpy()\n",
        "\n",
        "### for later use ###\n",
        "predicted_classes_logistic = predicted_classes\n",
        "target_classes_logistic = target_classes\n",
        "### --- ###\n",
        "\n",
        "con_mat_df = confusion_matrix(target_classes, predicted_classes, labels = [0,1,2])\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(con_mat_df)"
      ],
      "metadata": {
        "id": "P83jGZWCszed"
      },
      "id": "P83jGZWCszed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that all *setosa* samples in the validation set have been classified correctly (we knew this already from the plot of the decision boundary). The number of correct predictions was 6 (out of 10) for *versicolor* flowers, and 7 (out of 10) for *virginica*.\n",
        "\n",
        "It can be useful to visualize the confusion matrix in a plot:"
      ],
      "metadata": {
        "id": "hrJVkUiy5hP-"
      },
      "id": "hrJVkUiy5hP-"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sn.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FbgaBkeg6u5G"
      },
      "id": "FbgaBkeg6u5G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cohen's kappa\n",
        "\n",
        "We briefly introduce one additional metric to evaluate multiclass classification models, `Cohen's kappa` (or `k` coefficient) (more info <a href='https://en.wikipedia.org/wiki/Cohen%27s_kappa'>here</a>).\n",
        "\n",
        "We start from the results of the softmax regression model:\n",
        "\n",
        "`predicted_classes`\n",
        "\n",
        "`target_classes`"
      ],
      "metadata": {
        "id": "6q4FHDsMv5ou"
      },
      "id": "6q4FHDsMv5ou"
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_classes = predicted_classes.reshape(len(predicted_classes))\n",
        "target_classes = target_classes.reshape(len(target_classes))\n",
        "df = pd.DataFrame({'obs':target_classes, 'preds':predicted_classes})\n",
        "df['correct_prediction'] = df.apply(lambda row: row.obs == row.preds, axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "b7SeRcciuGP3"
      },
      "id": "b7SeRcciuGP3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that:\n",
        "\n",
        "- `0` = `setosa`\n",
        "- `1` = `versicolor`\n",
        "- `2` = `virginica`"
      ],
      "metadata": {
        "id": "uqQWQRXwxSs0"
      },
      "id": "uqQWQRXwxSs0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now count the number of correct predictions per class, and assign these numbers to variables:"
      ],
      "metadata": {
        "id": "5JSPdXcIxinh"
      },
      "id": "5JSPdXcIxinh"
    },
    {
      "cell_type": "code",
      "source": [
        "tbl = df.drop(columns = ['preds']).groupby('obs').sum('correct_prediction') ## summing True occurrences --> correct predictions\n",
        "tbl"
      ],
      "metadata": {
        "id": "BeCt9eZzxQMU"
      },
      "id": "BeCt9eZzxQMU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_setosa = tbl.loc[[0]]['correct_prediction'].item()\n",
        "true_versicolor = tbl.loc[[1]]['correct_prediction'].item()\n",
        "true_virginica = tbl.loc[[2]]['correct_prediction'].item()"
      ],
      "metadata": {
        "id": "UK5Y0ghLxnlx"
      },
      "id": "UK5Y0ghLxnlx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now calculate the total accuracy (n. of correct predictions over total number of predictions):"
      ],
      "metadata": {
        "id": "4JCtbT5xx2Zd"
      },
      "id": "4JCtbT5xx2Zd"
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = (true_setosa + true_versicolor + true_virginica)/len(predicted_classes_logistic)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "zhchU7ZXx21L"
      },
      "id": "zhchU7ZXx21L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is this the best metric to evaluate the performance of multiclass classification models?\n",
        "\n",
        "We already saw with binary classification that it is important also to look at **TPR** and **TNR**:\n",
        "- unbalanced data\n",
        "- specific classes may be more relevant\n",
        "\n",
        "Furthermore, the total (\"raw\") accuracy does not consider that correct predictions may also be obtained by **chance**!\n",
        "In binary classification, we know that (if data are balanced) the chance accuracy is 0.5.\n",
        "\n",
        "But what about multiclass classification? This is where **Cohen's kappa** comes into play.\n",
        "The `kappa coefficient` tries to consider how much better the predictive performance is over chance accuracy.\n",
        "\n",
        "To do so, we need to get some measure of the **expected value for chance accuracy**."
      ],
      "metadata": {
        "id": "1kAs49w7yOKF"
      },
      "id": "1kAs49w7yOKF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's calculate chance accuracy!\n",
        "\n",
        "We use the frequentist definition of probabilities:\n",
        "\n",
        "- chance predictions (relative frequencies of predictions, per class)\n",
        "- chance observations (relative class frequencies from the observed values)"
      ],
      "metadata": {
        "id": "C_9vtyw2yVPd"
      },
      "id": "C_9vtyw2yVPd"
    },
    {
      "cell_type": "code",
      "source": [
        "nums = df.groupby('preds').size()\n",
        "nums"
      ],
      "metadata": {
        "id": "YFrP1yNcyKQ1"
      },
      "id": "YFrP1yNcyKQ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chance_preds_setosa = nums.iloc[[0]].item()/len(df)\n",
        "chance_preds_versicolor = nums.iloc[[1]].item()/len(df)\n",
        "chance_preds_virginica = nums.iloc[[2]].item()/len(df)"
      ],
      "metadata": {
        "id": "ie5hQcZpyYPm"
      },
      "id": "ie5hQcZpyYPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chance_preds_setosa)\n",
        "print(chance_preds_versicolor)\n",
        "print(chance_preds_virginica)"
      ],
      "metadata": {
        "id": "L7qq2EIfyadf"
      },
      "id": "L7qq2EIfyadf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the test dataset is balanced, and all three classes have equal size (10 examples each): therefore chance observations are the same for all classes ($1/3$):"
      ],
      "metadata": {
        "id": "V-VJuVKZyfNs"
      },
      "id": "V-VJuVKZyfNs"
    },
    {
      "cell_type": "code",
      "source": [
        "nums = df.groupby('obs').size()\n",
        "nums"
      ],
      "metadata": {
        "id": "6tZ3qTfUyfsO"
      },
      "id": "6tZ3qTfUyfsO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chance_obs_setosa = 10/len(df)\n",
        "chance_obs_versicolor = 10/len(df)\n",
        "chance_obs_virginica = 10/len(df)"
      ],
      "metadata": {
        "id": "0vZaigZDyjhB"
      },
      "id": "0vZaigZDyjhB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now all set to calculate **chance accuracy**:"
      ],
      "metadata": {
        "id": "hfn5OkR0ymcD"
      },
      "id": "hfn5OkR0ymcD"
    },
    {
      "cell_type": "code",
      "source": [
        "chance_accuracy = chance_preds_setosa*chance_obs_setosa + chance_preds_versicolor*chance_obs_versicolor + chance_preds_virginica*chance_obs_virginica\n",
        "print(chance_accuracy)"
      ],
      "metadata": {
        "id": "VZ1p8Cj5ynuc"
      },
      "id": "VZ1p8Cj5ynuc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cohen's k\n",
        "\n",
        "And now, ladies and gentlemen, Cohen's k:\n",
        "\n",
        "$$\n",
        "k = \\frac{\\text{accuracy} - \\text{chance_accuracy}}{1 - \\text{chance_accuracy}}\n",
        "$$"
      ],
      "metadata": {
        "id": "hE-OBIoPyvL5"
      },
      "id": "hE-OBIoPyvL5"
    },
    {
      "cell_type": "code",
      "source": [
        "kappa = (accuracy-chance_accuracy) / (1 - chance_accuracy)\n",
        "print(kappa)"
      ],
      "metadata": {
        "id": "JRMqh9pyyvne"
      },
      "id": "JRMqh9pyyvne",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- the numerator calculates the difference between accuracy and chance accuracy\n",
        "- if accuracy = 1, we have perfect predictive performance (the confusion matrix is diagonal) $\\rightarrow$ $ k = 1$, regardless of chance accuracy\n",
        "- if accuracy = chance accuracy, $k=0$ $\\rightarrow$ correct predictions are by chance.\n",
        "- if accuracy < chance accuracy, $k < 0$ (negative) $\\rightarrow$ accuracy is lower than what it would be by chance."
      ],
      "metadata": {
        "id": "7LdGp2egy1hs"
      },
      "id": "7LdGp2egy1hs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luckily, we don't have to always do manually all these calculations: `sklearn` includes a function that caclulates **Cohen's kappa** for us:"
      ],
      "metadata": {
        "id": "WYbdq5LVy-Kv"
      },
      "id": "WYbdq5LVy-Kv"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "## test set\n",
        "k_test = cohen_kappa_score(predicted_classes_logistic,target_classes_logistic)\n",
        "print(\"Cohen kappa in the test set is: \", k_test)"
      ],
      "metadata": {
        "id": "0tWko_Y4y2CP"
      },
      "id": "0tWko_Y4y2CP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}