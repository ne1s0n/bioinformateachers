{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16f2f29e",
      "metadata": {
        "id": "16f2f29e"
      },
      "source": [
        "# One-layer neural network model for softmax regression (multiclass classification)\n",
        "\n",
        "[TODO]\n",
        "\n",
        "In this notebook, we extend logistic regression to multiclass classification using [softmax regression](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/#:~:text=Softmax%20regression%20(or%20multinomial%20logistic,kinds%20of%20hand%2Dwritten%20digits.) with.\n",
        "neural network implementation with one single layer (**softmax layer**).\n",
        "This is equivalent to a multinomial logistic regression model, only it is solved using neural networks (forward and backpropagation) rather than with maximum likelihood (or similar algorithms).\n",
        "\n",
        "As example data, we again use Fisher's [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6deb0024",
      "metadata": {
        "id": "6deb0024"
      },
      "source": [
        "Basically, a neural network implementation of softmax regression looks like graph below.\n",
        "There are as many units as classes in the multiclass classification problems (e.g. three classes in the *Iris* dataset: *Iris setos*, *Iris versicolor*, *Iris virginica*): each unit receives the vector of input features $\\mathbf{x}$ and multiplies it by a vector of weights $\\mathbf{w_u}$, specific to each unit $u$. The results are summed up together and the unit bias term $b_u$ is added. The real-valued $z_u$ variable is then activated with the *softmax* activation function to give the probability of belonging to the various classes of the problem.\n",
        "In other words, each unit performs a specific and independent linear combination of the input variables, and the outputs the probability of belonging to one class: i.e., each unit models the probability of one class given the data (e.g. $P(y=\\text{iris setosa}|x)$).\n",
        "\n",
        "<img src=\"softmax_layer.png\" alt=\"perceptron\" style=\"height: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries and setting the random seed\n",
        "\n",
        "First of all, we load some necessary libraries; then we setup the random seed to ensure reproducibility of results. Since tensorflow uses an internal random generator we need to fix both the general seed (via numpy `seed()`) and tensorflow seed (via `set_seet()`)"
      ],
      "metadata": {
        "id": "5Z63YlH0OgfH"
      },
      "id": "5Z63YlH0OgfH"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9e86c1bf",
      "metadata": {
        "id": "9e86c1bf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "  # Set the seed using keras.utils.set_random_seed. This will set:\n",
        "  # 1) `numpy` seed\n",
        "  # 2) `tensorflow` random seed\n",
        "  # 3) `python` random seed\n",
        "tf.keras.utils.set_random_seed(10)\n",
        "\n",
        "  # This will make TensorFlow ops as deterministic as possible, but it will\n",
        "  # affect the overall performance, so it's not enabled by default.\n",
        "  # `enable_op_determinism()` is introduced in TensorFlow 2.9.\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "From `sklearn.datasets` we get a \"bunch\" object that contains both the `target` and the `features` (to be accessed as attributes): `<dataset>.target` and `<dataset>.data`."
      ],
      "metadata": {
        "id": "zZ3vzxq4B0IQ"
      },
      "id": "zZ3vzxq4B0IQ"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "09318d92",
      "metadata": {
        "id": "09318d92"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "\n",
        "## 1)\n",
        "iris = sklearn.datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we convert data and features (originally as `numpy` arrays) to `pandas` dataframes / series"
      ],
      "metadata": {
        "id": "1rStMQUKDmt-"
      },
      "id": "1rStMQUKDmt-"
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data = pd.DataFrame(features, columns=iris.feature_names) #converting numpy array -> pandas DataFrame\n",
        "iris.target = pd.Series(target) #converting numpy array -> pandas Series"
      ],
      "metadata": {
        "id": "6jEcpPgtDDYh"
      },
      "id": "6jEcpPgtDDYh",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **iris** dataset is a historic dataset first used by **Ronald Fisher** in his 1936 paper on linear discriminant analysis (LDA).\n",
        "The dataset contains information on 150 flower samples, belonging to three species of Iris (Iris setosa, Iris virginica and Iris versicolor: the `target`).\n",
        "Four `features` were measured from each sample: the length and the width of the sepals and of the petals, in centimeters."
      ],
      "metadata": {
        "id": "Bpq4XO6UI_ta"
      },
      "id": "Bpq4XO6UI_ta"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "As said, the feature data has 150 rown and 4 columns:"
      ],
      "metadata": {
        "id": "FQp5ITO0KXKF"
      },
      "id": "FQp5ITO0KXKF"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of the feature table: ' + str(iris.data.shape))"
      ],
      "metadata": {
        "id": "BaEeW57GKZ9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa29975-0903-43f7-8c46-80d02a772dee"
      },
      "id": "BaEeW57GKZ9E",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the feature table: (150, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes are represented via a numeric index: 0 for *setosa*, 1 for *versicolor*, 2 for *virginica*. The samples are in order: the first 50 samples are *setosa*, then 50 *versicolor* and the last 50 are *virginica*.\n",
        "\n",
        "When working with a new dataset, it is always importat to plot the data. We are unfortunately talking about a 5-dimensional dataset (the four features + the target class) which is not easily representable.\n",
        "One possibility is to take a slice (a subset) of the whole dataset.\n",
        "\n",
        "In the next code chunk we plot two features plus the class."
      ],
      "metadata": {
        "id": "OBMUK3_NL5bI"
      },
      "id": "OBMUK3_NL5bI"
    },
    {
      "cell_type": "code",
      "source": [
        "## SELECT FEATURES TO PLOT\n",
        "#change these two values to plot different features, remembering the numbering:\n",
        "# 0 : sepal length (cm)\n",
        "# 1 : sepal width (cm)\n",
        "# 2 : petal length (cm)\n",
        "# 3 : petal width (cm)\n",
        "feature_x = 0\n",
        "feature_y = 1\n",
        "\n",
        "#starting a new plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "#adding data in three bunches of 50, once per class\n",
        "ax.scatter(x=iris.data.iloc[0:50,feature_x],    y=iris.data.iloc[0:50,feature_y],    c='red',   label=iris.target_names[0])\n",
        "ax.scatter(x=iris.data.iloc[50:100,feature_x],  y=iris.data.iloc[50:100,feature_y],  c='green', label=iris.target_names[1])\n",
        "ax.scatter(x=iris.data.iloc[100:150,feature_x], y=iris.data.iloc[100:150,feature_y], c='blue',  label=iris.target_names[2])\n",
        "\n",
        "#the axis names are taken from feature names\n",
        "ax.set_xlabel(iris.feature_names[feature_x])\n",
        "ax.set_ylabel(iris.feature_names[feature_y])\n",
        "\n",
        "#adding the legend and printing the plot\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KrqLvYQWNav_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "e027779b-a7ab-4c89-e0c6-ac33537cccd3"
      },
      "id": "KrqLvYQWNav_",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time, we are going to use all three classes as they are."
      ],
      "metadata": {
        "id": "PawFSrXlNwe_"
      },
      "id": "PawFSrXlNwe_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem is that our target array `iris.target` is a numeric array (e.g. [1 0 0 2 1 1 0 ...]).\n",
        "However teose numbers (0, 1, and 2) do not represent real values. In other words, \"virginica\" is not twice \"versicolor\". Numbers here are used as labels, not as quantities.\n",
        "\n",
        "As a matter of fact, to properly train a model the structure of the target array must be changed to [one-hot encoding](https://en.wikipedia.org/wiki/One-hot). In simple terms, it needs to become a table with one row per sample (150 in total) and one column per class (three in total). Something like:\n",
        "\n",
        "| Setosa | Versicolor | Virginica |\n",
        "|------|------|------|\n",
        "|   0  |   1  |   0  |\n",
        "|   1  |   0  |   0  |\n",
        "|   1  |   0  |   0  |\n",
        "|   0  |   0  |   1  |\n",
        "\n",
        "As you can see the first sample is Versicolor, the second and third are Setosa, the last one is Virginica. Note that there is only a single \"one\" per row.\n",
        "\n",
        "We need to do a little **preprocessing**."
      ],
      "metadata": {
        "id": "7gRqeggVWVW1"
      },
      "id": "7gRqeggVWVW1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "As said, we need to convert a numeric vector to a one-hot encoding (OHE) representation.\n",
        "Luckily, it's easy to pass to one-hot encode using the keras function [to_categorical](https://keras.io/api/utils/python_utils/#to_categorical-function):\n",
        "\n",
        "To make the problem a little more challenging (and interesting) we decide to **drop half of the features**, **using only the first two** columns."
      ],
      "metadata": {
        "id": "zD4xK76sOajn"
      },
      "id": "zD4xK76sOajn"
    },
    {
      "cell_type": "code",
      "source": [
        "#the \"utils\" subpackage is very useful, take a look to it when you have time\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "#converting to categorical\n",
        "target_multi_cat = tf.keras.utils.to_categorical(target)\n",
        "\n",
        "#since everything else is a Pandas dataframe, let's stick to the format\n",
        "#for consistency\n",
        "target_multi_cat = pd.DataFrame(target_multi_cat)\n",
        "\n",
        "#let's take a look\n",
        "print(target_multi_cat)"
      ],
      "metadata": {
        "id": "SfSXs5pZOaDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1207ab84-2f70-4897-d62e-6fcfb3ab42f9"
      },
      "id": "SfSXs5pZOaDO",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       0    1    2\n",
            "0    1.0  0.0  0.0\n",
            "1    1.0  0.0  0.0\n",
            "2    1.0  0.0  0.0\n",
            "3    1.0  0.0  0.0\n",
            "4    1.0  0.0  0.0\n",
            "..   ...  ...  ...\n",
            "145  0.0  0.0  1.0\n",
            "146  0.0  0.0  1.0\n",
            "147  0.0  0.0  1.0\n",
            "148  0.0  0.0  1.0\n",
            "149  0.0  0.0  1.0\n",
            "\n",
            "[150 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get the first two features, to make the example comparable with the previous notebook on binary classification"
      ],
      "metadata": {
        "id": "vBM2GqsHZrK4"
      },
      "id": "vBM2GqsHZrK4"
    },
    {
      "cell_type": "code",
      "source": [
        "features = iris.data.iloc[:,0:2] ## we are selecting the first two features / columns"
      ],
      "metadata": {
        "id": "htJv49_hSXN6"
      },
      "id": "htJv49_hSXN6",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation sets\n",
        "\n",
        "Each time there is some kind of \"learning\" involved we need to split our data. A subset will be used for training, and a subset will be used for validation.\n",
        "\n",
        "In our current dataset the samples are sorted by class: the first 100 are \"non-virginica\" and the remaining 50 are \"virginica\".\n",
        "We want to keep this 2:1 proportion (roughly) the same in both train and validation set.\n",
        "\n",
        "Obviously (given the ordered data), taking the first $80\\%$ (120 samples) of the data as training and the rest (30 samples) as validation would be a bad choice ... (only 'virginica' samples in the validation set, 4:1 class proportion in the training set).   \n",
        "\n",
        "Simple random sampling would also not be a good solution, since the 2:1 proportion will not be maintained.\n",
        "\n",
        "Therefore we are going to use what is called a [stratified approach](https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/) using a [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) object from `scikit-learn`:\n"
      ],
      "metadata": {
        "id": "K98ZAN9-S4a8"
      },
      "id": "K98ZAN9-S4a8"
    },
    {
      "cell_type": "code",
      "source": [
        "#we want to have the same proportion of classes in both train and validation sets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "test_pct = 0.2\n",
        "\n",
        "#building a StratifiedShuffleSplit object (sss among friends) with 20% data\n",
        "#assigned to validation set (here called \"test\")\n",
        "#random_state is used to control class balance between training and test sets (None to switch to random behavior)\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size= test_pct, random_state=0)\n",
        "\n",
        "for train_index, val_index in sss.split(features, target_multi_cat):\n",
        "    features_train = features.iloc[train_index, :]\n",
        "    features_val   = features.iloc[val_index, :]\n",
        "    target_train   = target_multi_cat.iloc[train_index, :]\n",
        "    target_val     = target_multi_cat.iloc[val_index, :]"
      ],
      "metadata": {
        "id": "Zz1Miz6TSw84"
      },
      "id": "Zz1Miz6TSw84",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shapes\n",
        "print(features_train.shape)\n",
        "print(features_val.shape)\n",
        "print(target_train.shape)\n",
        "print(target_val.shape)\n",
        "\n",
        "#number of classes per split\n",
        "print('\\nClasses in train set:')\n",
        "print(target_train.sum())\n",
        "print('\\nClasses in validation set:')\n",
        "print(target_val.sum())"
      ],
      "metadata": {
        "id": "IAMFHDFIVD1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c02291-95e6-4314-ac22-fdc39a348ba4"
      },
      "id": "IAMFHDFIVD1L",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 2)\n",
            "(30, 2)\n",
            "(120, 3)\n",
            "(30, 3)\n",
            "\n",
            "Classes in train set:\n",
            "0    40.0\n",
            "1    40.0\n",
            "2    40.0\n",
            "dtype: float32\n",
            "\n",
            "Classes in validation set:\n",
            "0    10.0\n",
            "1    10.0\n",
            "2    10.0\n",
            "dtype: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that we have $80\\%$ data ready for training and $20\\%$ for validation, both sets with a 2:1 target class ratio: job done!"
      ],
      "metadata": {
        "id": "mki_AVWuVGjh"
      },
      "id": "mki_AVWuVGjh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the neural network model\n",
        "\n",
        "We want to use a neural network model for logistic regression.\n",
        "There are many `Python` frameworks that implement (Deep) Neural Networks: here we are using `Keras` (for more details on how to use *keras* a good starting point is the [documentation on training and evaluation](https://www.tensorflow.org/guide/keras/train_and_evaluate)).\n",
        "\n",
        "Our neural network will be very minimal, as illustrated in the sketch at the beginning of this notebook: it will be comprised of only one node (neuron) that will perform both 1) the linear combination of weighted input variables + bias term; and 2) activate the result of step 1 with the sigmoid function to produce the probability of belonging to class \"1\" (or \"0\").\n",
        "\n",
        "We are now ready to build the NN (neural network) model!\n",
        "\n",
        "- model set-up\n",
        "- model architecture and compiling"
      ],
      "metadata": {
        "id": "ecoydX0bVgMx"
      },
      "id": "ecoydX0bVgMx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model set-up\n",
        "\n",
        "We first need to define some hyperparameters:\n",
        "\n",
        "1. activation function (`sigmoid`, this is a binary classification problem)\n",
        "2. optimizer (the algorithm that carries out forward and backpropagation to solve the model)\n",
        "3. the loss function (`binary cross-entropy`, again this is binary classification!)"
      ],
      "metadata": {
        "id": "JHec8oN7cxvy"
      },
      "id": "JHec8oN7cxvy"
    },
    {
      "cell_type": "code",
      "source": [
        "activation_function = 'sigmoid'\n",
        "optimizing_method = 'rmsprop'\n",
        "loss_function = 'binary_crossentropy'"
      ],
      "metadata": {
        "id": "_mPrv77YVSwo"
      },
      "id": "_mPrv77YVSwo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture\n",
        "\n",
        "This is a one-layer one-unit neural network model.\n",
        "The neural network is fully connected, meaning that the unit receives in input all features."
      ],
      "metadata": {
        "id": "HAbTw4oDdSMS"
      },
      "id": "HAbTw4oDdSMS"
    },
    {
      "cell_type": "code",
      "source": [
        "#we are building a \"sequential\" model, meaning that the data will\n",
        "#flow like INPUT -> ELABORATION -> OUTPUT. In particular, we will\n",
        "#not have any loops, i.e. our output will never be recycled as\n",
        "#input for the first layer\n",
        "from keras.models import Sequential\n",
        "\n",
        "#a \"dense\" layer is a layer were all the data coming in are connected\n",
        "#to all nodes (fully connected).\n",
        "#In our case there is only one node in the layer, and\n",
        "#it receives all the input features\n",
        "from keras.layers import Dense\n",
        "\n",
        "# 2-class logistic regression in Keras\n",
        "model = Sequential()\n",
        "model.add(Dense(units=1, activation='sigmoid', input_dim=features_train.shape[1]))\n",
        "\n",
        "#the model is declared, but we still need to compile it to actually\n",
        "#build all the data structures\n",
        "model.compile(optimizer=optimizing_method, loss=loss_function)"
      ],
      "metadata": {
        "id": "LlgkOZuudTvT"
      },
      "id": "LlgkOZuudTvT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the `.summary()` method we can take a look inside the model:"
      ],
      "metadata": {
        "id": "Awoe08PBd_HG"
      },
      "id": "Awoe08PBd_HG"
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "NKOLG-tWd6o5"
      },
      "id": "NKOLG-tWd6o5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are three trainable parameters (the weights for the two input variables, W1, W2, plus the bias term 'B'), and a single node.\n",
        "The output is a single number. Excellent."
      ],
      "metadata": {
        "id": "LQlHhEv7eHrC"
      },
      "id": "LQlHhEv7eHrC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the neural network model\n",
        "\n",
        "Now that the model has been built and compiled, we are ready to train it on the data.\n",
        "Training is an iterative process that cycles many times through what are called `epochs`. Remeber: one epoch is one cycle of forward and backward propagation.\n",
        "\n",
        "We'll start with only ten epochs, to get the gist of it (and we print out the standard output to monitor the process):"
      ],
      "metadata": {
        "id": "bMoZEu_phn7j"
      },
      "id": "bMoZEu_phn7j"
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(features_train, target_train, epochs=10, validation_data=(features_val, target_val))"
      ],
      "metadata": {
        "id": "OzRyL84ud7El"
      },
      "id": "OzRyL84ud7El",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We asked for ten epochs and the network did just that. At each iteration the network is trying really hard to minimize the [\"loss\"](https://keras.io/api/losses/). The specifics are defined by our choice of loss function (we selected `binary_crossentropy`). The basic idea is that the smaller the loss the better the fit.\n",
        "\n",
        "Note that the network minimizes the loss on the training set and does not use the validation set during the learning process. It can however measure the loss on the validation set to give us an idea on how well it can generalize on new data.\n",
        "\n",
        "It's handy at this point to define a function that takes in the `history` object returned by `.fit()` and plots it:"
      ],
      "metadata": {
        "id": "5gbvbxc6jmqa"
      },
      "id": "5gbvbxc6jmqa"
    },
    {
      "cell_type": "code",
      "source": [
        "#function to take a look at losses evolution\n",
        "def plot_loss_history(h, title):\n",
        "    plt.plot(h.history['loss'], label = \"Train loss\")\n",
        "    plt.plot(h.history['val_loss'], label = \"Validation loss\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "siu0zjjehvFf"
      },
      "id": "siu0zjjehvFf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_history(history, 'Logistic (10 epochs)')"
      ],
      "metadata": {
        "id": "pVKSJX8ShxPh"
      },
      "id": "pVKSJX8ShxPh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The good news is that the loss just goes down, both in train and validation set. We can keep training - without recompiling, we just add new epochs to our network."
      ],
      "metadata": {
        "id": "nwdeKHYpj4X_"
      },
      "id": "nwdeKHYpj4X_"
    },
    {
      "cell_type": "code",
      "source": [
        "#putting verbose to 0 to avoid filling the screen\n",
        "history2 = model.fit(features_train, target_train, epochs=190,\n",
        "                     validation_data=(features_val, target_val), verbose=0)"
      ],
      "metadata": {
        "id": "do6J-enfj8T1"
      },
      "id": "do6J-enfj8T1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if (and by how much) we improved our training:"
      ],
      "metadata": {
        "id": "mjjdxUj1kGNe"
      },
      "id": "mjjdxUj1kGNe"
    },
    {
      "cell_type": "code",
      "source": [
        "#putting together the whole history\n",
        "history.history['loss'] += history2.history['loss']\n",
        "history.history['val_loss'] += history2.history['val_loss']\n",
        "\n",
        "#and plotting again\n",
        "plot_loss_history(history, 'Logistic (500 epochs)')"
      ],
      "metadata": {
        "id": "Mg_MJ3q5kFdi"
      },
      "id": "Mg_MJ3q5kFdi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is very informative: the loss keeps decreasing, meaning that the network keeps improving. However after a first phase of steep improvement the gain for each epoch slows down considerably (diminishing returns).\n",
        "\n",
        "Additionally, we now see a clear difference between what happens in the training and in the validation sets. This means that, while the network keeps improving, its performance on new data is expected to be worse than that on the training data (as theoretically expected: training by the book!).\n",
        "\n",
        "We can now ask ourselves: what happens if we keep training for a long time? We have prepared the code for 10000 epochs, but it takes a long time to run, and it's faster if we simply show the saved results (but you can try to run it putting the following flag to `True`):"
      ],
      "metadata": {
        "id": "-rUceSeikP6c"
      },
      "id": "-rUceSeikP6c"
    },
    {
      "cell_type": "code",
      "source": [
        "do_10000_epochs = False"
      ],
      "metadata": {
        "id": "vtHe-PEWk1Za"
      },
      "id": "vtHe-PEWk1Za",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what happens if we keep going for a (very) long time?\n",
        "if (do_10000_epochs):\n",
        "    #train for 10000 epochs, just to show how the model evolves\n",
        "    history3 = model.fit(features_train, target_train, epochs=9500,\n",
        "                         validation_data=(features_val, target_val), verbose=0)\n",
        "\n",
        "    #putting together the whole history\n",
        "    history.history['loss'] += history3.history['loss']\n",
        "    history.history['val_loss'] += history3.history['val_loss']\n",
        "\n",
        "    #and plotting again\n",
        "    plot_loss_history(history, 'Logistic (10000 epochs)')"
      ],
      "metadata": {
        "id": "V3i5iLNUk5co"
      },
      "id": "V3i5iLNUk5co",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pre-recorded results look like this:\n",
        "\n",
        "![regression_10000_epochs](regression_loss10000.png)\n",
        "\n",
        "It appears that there is constant, slow improvement on the training set. Improvement on validation set is slower, and if we had the patience to go for a veeeery long time the orange curve would become completely flat."
      ],
      "metadata": {
        "id": "YhO2qhx4lCAc"
      },
      "id": "YhO2qhx4lCAc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation\n",
        "\n",
        "Any model is only useful when it's used to predict new, unknown data. In fact the whole validation set was put apart and not really used for training for this specific reason.\n",
        "\n",
        "There are several ways in which a neural network model (or any model for that matter!) can be evaluated.\n",
        "Here we look at a few approaches:\n",
        "\n",
        "- decision boundary\n",
        "- error-rate / accuracy\n",
        "- confusion matrix"
      ],
      "metadata": {
        "id": "brqzSW3wlmOp"
      },
      "id": "brqzSW3wlmOp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Boundary\n",
        "\n",
        "Based on the model fit, we can plot the decision boundary, i.e. a representation in the two-dimensional feature space of the criterion that the model is using to classify the data in the two classes (`virginica` and `non-virginica` flowers).\n",
        "For this task we'll use the [mlxtend module](http://rasbt.github.io/mlxtend/), which unfortunately does not usually come with the standard installation. Let's add it!"
      ],
      "metadata": {
        "id": "Q1tXDHkGmR13"
      },
      "id": "Q1tXDHkGmR13"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend ##execute shell command"
      ],
      "metadata": {
        "id": "kdfsi_Uvk9IO"
      },
      "id": "kdfsi_Uvk9IO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "#we'll print the training set\n",
        "plot_decision_regions(X = features_val.to_numpy(), y = target_val.to_numpy(), clf=model)\n",
        "plt.title('Decision boundary for 0 (non virginica) vs 1 (virginica) flowers')\n",
        "plt.xlabel(iris.feature_names[feature_x])\n",
        "plt.ylabel(iris.feature_names[feature_y])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vpoxza6DnNbP"
      },
      "id": "Vpoxza6DnNbP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The colored areas (yellow, blue) represent the behaviour of the trained model; the blue squares and yellow triangles are the actual samples in the validation set.\n",
        "\n",
        "The **decision boundary is linear**, as expected by logistic regression. This means that all samples in the pink area will be classified as 1 (virginica) and all points in the blue area be considered 0 (non virginica).\n",
        "\n",
        "Note that relatively many virginica samples are in the blue area compared to the numer of non-virginica present in the pink area. Also note that, roughly speaking, the regressor assigned a wider area to non-virginica. This is a direct consequence of having an unbalanced dataset: two-thirds of the samples are non-virginica (blue squares) and one-third are virginica (red triangles). **The resulting regressor is polarised** towards the more numerous class."
      ],
      "metadata": {
        "id": "F7ZHPR7BnYNY"
      },
      "id": "F7ZHPR7BnYNY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error rate / accuracy\n",
        "\n",
        "To calculate the accuracy of the trained neural network model for binary classification, we first need to get the predictions made on the validation set.\n",
        "Luckily, it's very easy to apply a trained model to new data (the validation set) via the [predict() method](https://keras.io/api/models/model_training_apis/#predict-method).\n",
        "\n",
        "We can thus get our prediction for the iris flowers (see below):"
      ],
      "metadata": {
        "id": "1tXXdV6m4pnK"
      },
      "id": "1tXXdV6m4pnK"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(features_val)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "Lzvgmz1noEbF"
      },
      "id": "Lzvgmz1noEbF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What do these numbers (the predictions) represent?** If you remember, in logistic regression we are modelling $P(y=1|x)$ (in short, $p(x)$), the probability for a sample of belonging to class \"1\" given the data `x`.\n",
        "\n",
        "If we use the **0.5 threshold** to assign samples to the two classes (a very natural choice), we will say that a sample belongs to class \"0\" (`non-virginica`) if $P(x) < 0.5$, or to class \"1\" (`virginica`) if $p(x) > 0.5$.\n",
        "\n",
        "Then, we can compare the predicted and true classes in the validation set and count the errors (remember, this is supervised learning, we know the \"answers\"!).\n"
      ],
      "metadata": {
        "id": "hrJVkUiy5hP-"
      },
      "id": "hrJVkUiy5hP-"
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class = np.where(predictions > 0.5, \"virginica\", \"non-virginica\")\n",
        "target_class = np.where(target_val == 1, \"virginica\", \"non-virginica\")\n",
        "target_class = target_class.reshape(len(target_class),1)\n",
        "\n",
        "results = target_class == predicted_class"
      ],
      "metadata": {
        "id": "FbgaBkeg6u5G"
      },
      "id": "FbgaBkeg6u5G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now count the number of errors and of correct predictions, and from these the error rate and the accuracy as simple ratios on the total number of predictions:"
      ],
      "metadata": {
        "id": "C3Oj8ubw8dkY"
      },
      "id": "C3Oj8ubw8dkY"
    },
    {
      "cell_type": "code",
      "source": [
        "errors = np.invert(results).sum()\n",
        "correct_predictions = results.sum()\n",
        "total_n_predictions = len(results)\n",
        "\n",
        "print(\"Error rate:\", round(errors/total_n_predictions, 3))\n",
        "print(\"Accuracy:\", round(correct_predictions/total_n_predictions, 3))"
      ],
      "metadata": {
        "id": "2Ky3UlRO7M3A"
      },
      "id": "2Ky3UlRO7M3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix\n",
        "\n",
        "Besides the overall error rate / accuracy, it is always a good idea to look at the errors in the two classes.\n",
        "This is especially important when data are unbalanced. We can have a more comprehensive assessment of the performance of the classification model by looking at the **confusion matrix** (more details <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">here</a>)."
      ],
      "metadata": {
        "id": "R3F37lm09MBY"
      },
      "id": "R3F37lm09MBY"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = ['non-virginica','virginica']\n",
        "con_mat_df = confusion_matrix( y_true = target_class, y_pred = predicted_class, labels=labels) #true are rows, predicted are columns\n",
        "pd.DataFrame(\n",
        "    con_mat_df,\n",
        "    index = ['true:'+x for x in labels],\n",
        "    columns = ['pred:'+x for x in labels])"
      ],
      "metadata": {
        "id": "rqL1KNu4-PgB"
      },
      "id": "rqL1KNu4-PgB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Along the diagonal of the confusion matrix we have the correct predictions, off the diagonal the errors.\n",
        "\n",
        "We see that 7 virginica flowers have been wrongly predicted as non-virginica flowers, and 3 non-virginica flowers have been wrongly predicted as virginica flowers.\n",
        "\n",
        "It is apparent that the unblancedness of the data has skewed predictions in favor of non-virginica flowers, the most common type of flowers in the data (twice as much).\n",
        "\n",
        "We can express this \"bias\" by measuring the accuracy in the two classes:\n",
        "\n",
        "- **True positive rate** (**TPR**): the proportion of correct predictions in the positive class (class `1`, here virginica) $\\rightarrow$ TP/(TP+FN) = 3/(3+7) = 3/10 = 0.333\n",
        "- **True negative rate** (**TNR**): the proportion of correct predictions in the negative class (class `0`, here non-virginica) $\\rightarrow$ TN/(TN+FP) = 17/(17+3) = 17/20 = 0.85"
      ],
      "metadata": {
        "id": "IZS1iwxv-9Eg"
      },
      "id": "IZS1iwxv-9Eg"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}