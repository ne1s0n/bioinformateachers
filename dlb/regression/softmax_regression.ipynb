{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16f2f29e",
      "metadata": {
        "id": "16f2f29e"
      },
      "source": [
        "# One-layer neural network model for softmax regression (multiclass classification)\n",
        "\n",
        "[TODO]\n",
        "\n",
        "In this notebook, we illustrate how to do [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression)\n",
        "using a neural network-like implementation with one single unit (perceptron).\n",
        "This is equivalent to a logistic regression model, only it is solved using neural networks (forward and backpropagation) rather than with maximum likelihood (or similar algorithms).\n",
        "\n",
        "As example data, we use the famous [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6deb0024",
      "metadata": {
        "id": "6deb0024"
      },
      "source": [
        "Basically, a neural network implementation of logistic regression will look like the sketch below: first, the vector of input features $\\mathbf{x}$ is multiplied by the vector of weights $\\mathbf{w}$, the results are summed up together and the bias term $b$ is added. This will return the real-valued variable $z$ in the interval $[\\pm âˆž]$.\n",
        "Then, $z$ is activated with the logistic (sigmoid) function $\\rightarrow \\sigma(z)$ to give $P(y=1|x)$, the probability of belonging to class `1` given the input features $x$.\n",
        "\n",
        "<img src=\"softmax_layer.png\" alt=\"perceptron\" style=\"height: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries and setting the random seed\n",
        "\n",
        "First of all, we load some necessary libraries; then we setup the random seed to ensure reproducibility of results. Since tensorflow uses an internal random generator we need to fix both the general seed (via numpy `seed()`) and tensorflow seed (via `set_seet()`)"
      ],
      "metadata": {
        "id": "5Z63YlH0OgfH"
      },
      "id": "5Z63YlH0OgfH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e86c1bf",
      "metadata": {
        "id": "9e86c1bf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "  # Set the seed using keras.utils.set_random_seed. This will set:\n",
        "  # 1) `numpy` seed\n",
        "  # 2) `tensorflow` random seed\n",
        "  # 3) `python` random seed\n",
        "tf.keras.utils.set_random_seed(10)\n",
        "\n",
        "  # This will make TensorFlow ops as deterministic as possible, but it will\n",
        "  # affect the overall performance, so it's not enabled by default.\n",
        "  # `enable_op_determinism()` is introduced in TensorFlow 2.9.\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "From `sklearn.datasets` there are generally two ways to import the data:\n",
        "\n",
        "1. `return_X_y = False` (default): returns a \"bunch\" object that contains both the `target` and the `features` (to be accessed as attributes): `<dataset>.target` and `<dataset>.data`\n",
        "2. `return_X_y = True`: returns directly the target and features separately"
      ],
      "metadata": {
        "id": "zZ3vzxq4B0IQ"
      },
      "id": "zZ3vzxq4B0IQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09318d92",
      "metadata": {
        "id": "09318d92"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "\n",
        "## 1)\n",
        "iris = sklearn.datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we convert data and features (originally as `numpy` arrays) to `pandas` dataframes / series"
      ],
      "metadata": {
        "id": "1rStMQUKDmt-"
      },
      "id": "1rStMQUKDmt-"
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data = pd.DataFrame(features, columns=iris.feature_names) #converting numpy array -> pandas DataFrame\n",
        "iris.target = pd.Series(target) #converting numpy array -> pandas Series"
      ],
      "metadata": {
        "id": "6jEcpPgtDDYh"
      },
      "id": "6jEcpPgtDDYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **iris** dataset is a historic dataset first used by **Ronald Fisher** in his 1936 paper on linear discriminant analysis (LDA).\n",
        "The dataset contains information on 150 flower samples, belonging to three species of Iris (Iris setosa, Iris virginica and Iris versicolor: the `target`).\n",
        "Four `features` were measured from each sample: the length and the width of the sepals and of the petals, in centimeters."
      ],
      "metadata": {
        "id": "Bpq4XO6UI_ta"
      },
      "id": "Bpq4XO6UI_ta"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "As said, the feature data has 150 rown and 4 columns:"
      ],
      "metadata": {
        "id": "FQp5ITO0KXKF"
      },
      "id": "FQp5ITO0KXKF"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of the feature table: ' + str(iris.data.shape))"
      ],
      "metadata": {
        "id": "BaEeW57GKZ9E"
      },
      "id": "BaEeW57GKZ9E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The four features are real-valued numbers in the $10^1$ range:"
      ],
      "metadata": {
        "id": "5aduLrMQK8cG"
      },
      "id": "5aduLrMQK8cG"
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data.describe()"
      ],
      "metadata": {
        "id": "LQPPnwo3KvYE"
      },
      "id": "LQPPnwo3KvYE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `target` is a vector (`pandas` series) of integers (0, 1, 2), one for each flower species (50 samples each):"
      ],
      "metadata": {
        "id": "Gr_okx7eLJ_t"
      },
      "id": "Gr_okx7eLJ_t"
    },
    {
      "cell_type": "code",
      "source": [
        "#using Counter object to print a tally of the classes\n",
        "from collections import Counter\n",
        "print('Numerosity for each class: ' + str(Counter(iris.target)))"
      ],
      "metadata": {
        "id": "dZme8IZ0LF6R"
      },
      "id": "dZme8IZ0LF6R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes are represented via a numeric index: 0 for *setosa*, 1 for *versicolor*, 2 for *virginica*. The samples are in order: the first 50 samples are *setosa*, then 50 *versicolor* and the last 50 are *virginica*.\n",
        "\n",
        "When working with a new dataset, it is always importat to plot the data. We are unfortunately talking about a 5-dimensional dataset (the four features + the target class) which is not easily representable.\n",
        "One possibility is to take a slice (a subset) of the whole dataset.\n",
        "\n",
        "In the next code chunk we plot two features plus the class."
      ],
      "metadata": {
        "id": "OBMUK3_NL5bI"
      },
      "id": "OBMUK3_NL5bI"
    },
    {
      "cell_type": "code",
      "source": [
        "## SELECT FEATURES TO PLOT\n",
        "#change these two values to plot different features, remembering the numbering:\n",
        "# 0 : sepal length (cm)\n",
        "# 1 : sepal width (cm)\n",
        "# 2 : petal length (cm)\n",
        "# 3 : petal width (cm)\n",
        "feature_x = 0\n",
        "feature_y = 1\n",
        "\n",
        "#starting a new plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "#adding data in three bunches of 50, once per class\n",
        "ax.scatter(x=iris.data.iloc[0:50,feature_x],    y=iris.data.iloc[0:50,feature_y],    c='red',   label=iris.target_names[0])\n",
        "ax.scatter(x=iris.data.iloc[50:100,feature_x],  y=iris.data.iloc[50:100,feature_y],  c='green', label=iris.target_names[1])\n",
        "ax.scatter(x=iris.data.iloc[100:150,feature_x], y=iris.data.iloc[100:150,feature_y], c='blue',  label=iris.target_names[2])\n",
        "\n",
        "#the axis names are taken from feature names\n",
        "ax.set_xlabel(iris.feature_names[feature_x])\n",
        "ax.set_ylabel(iris.feature_names[feature_y])\n",
        "\n",
        "#adding the legend and printing the plot\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KrqLvYQWNav_"
      },
      "id": "KrqLvYQWNav_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot shows clearly that setosa is quite separate from the other two classes. Whichever features you choose for the plot, you more or less get this same general result.\n",
        "\n",
        "This is however a **three-class** problem: however, we want to build a **neural network model** for **logistic regression** applied to a **binary classification problem**.\n",
        "\n",
        "Therefore, we need some preparatory ('preprocessing') steps."
      ],
      "metadata": {
        "id": "PawFSrXlNwe_"
      },
      "id": "PawFSrXlNwe_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "We need to transform a **three-class problem in a two-class problem**: we choose to **join together Setosa and Versicolor** (the red and green dots from the plot above), which appear to be less obviously separable based on sepal (and petal) length and width (and hence promise to provide more of a challenge to our neural network problem).\n",
        "In other words, we want to build a classifier able to discriminate `virginica` (which becomes the new class \"1\") from the other `non-virginica` flowers (which all together become the new class \"0\").\n",
        "\n",
        "To make the problem a little more challenging (and interesting) we decide to **drop half of the features**, **using only the first two** columns."
      ],
      "metadata": {
        "id": "zD4xK76sOajn"
      },
      "id": "zD4xK76sOajn"
    },
    {
      "cell_type": "code",
      "source": [
        "#simplifly the problem: less classes, less features\n",
        "features = iris.data.iloc[:, 0:2]\n",
        "target = iris.target\n",
        "\n",
        "#updating class labels. To makes things difficult we put together old classes 0 and 1\n",
        "#in a new class (non virginica) and keep old class 2 (virginica) as new class 1.\n",
        "#For an easier problems put together versicolor and virginica and keep setosa by itself\n",
        "j = 100 ## split: 50 for setosa vs versicolor+virginica, 100 for setosa+versicolor vs virginica\n",
        "target[0:j] = 0\n",
        "target[j:150] = 1"
      ],
      "metadata": {
        "id": "SfSXs5pZOaDO"
      },
      "id": "SfSXs5pZOaDO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#starting a new plot\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "#adding data in two bunches\n",
        "ax.scatter(x=features.iloc[0:j,0],   y=features.iloc[0:j,1],   c='red',  label='non-virginica')\n",
        "ax.scatter(x=features.iloc[j:150,0], y=features.iloc[j:150,1], c='blue', label='virginica')\n",
        "\n",
        "#the axis names are taken from feature names\n",
        "ax.set_xlabel(iris.feature_names[feature_x])\n",
        "ax.set_ylabel(iris.feature_names[feature_y])\n",
        "\n",
        "# displaying the title\n",
        "plt.title(\"Two-class simplified problem\")\n",
        "\n",
        "#adding the legend and printing the plot\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "htJv49_hSXN6"
      },
      "id": "htJv49_hSXN6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things are getting interesting! This is now a difficult problem and there is no clear cut solution. Let's proceed."
      ],
      "metadata": {
        "id": "homZQT2rS2AI"
      },
      "id": "homZQT2rS2AI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and validation sets\n",
        "\n",
        "Each time there is some kind of \"learning\" involved we need to split our data. A subset will be used for training, and a subset will be used for validation.\n",
        "\n",
        "In our current dataset the samples are sorted by class: the first 100 are \"non-virginica\" and the remaining 50 are \"virginica\".\n",
        "We want to keep this 2:1 proportion (roughly) the same in both train and validation set.\n",
        "\n",
        "Obviously (given the ordered data), taking the first $80\\%$ (120 samples) of the data as training and the rest (30 samples) as validation would be a bad choice ... (only 'virginica' samples in the validation set, 4:1 class proportion in the training set).   \n",
        "\n",
        "Simple random sampling would also not be a good solution, since the 2:1 proportion will not be maintained.\n",
        "\n",
        "Therefore we are going to use what is called a [stratified approach](https://machinelearningmastery.com/cross-validation-for-imbalanced-classification/) using a [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html) object from `scikit-learn`:\n"
      ],
      "metadata": {
        "id": "K98ZAN9-S4a8"
      },
      "id": "K98ZAN9-S4a8"
    },
    {
      "cell_type": "code",
      "source": [
        "#we want to have the same proportion of classes in both train and validation sets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "#building a StratifiedShuffleSplit object (sss among friends) with 20% data\n",
        "#assigned to validation set (here called \"test\")\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
        "\n",
        "#the .split() method returns (an iterable over) two lists which can be\n",
        "#used to index the samples that go into train and validation sets\n",
        "for train_index, val_index in sss.split(features, target):\n",
        "    features_train = features.iloc[train_index, :]\n",
        "    features_val   = features.iloc[val_index, :]\n",
        "    target_train   = target[train_index]\n",
        "    target_val     = target[val_index]\n",
        "\n",
        "#let's print some shapes to get an idea of the resulting data structure\n",
        "print(features_train.shape)\n",
        "print(features_val.shape)\n",
        "print(target_train.shape)\n",
        "print(target_val.shape)"
      ],
      "metadata": {
        "id": "Zz1Miz6TSw84"
      },
      "id": "Zz1Miz6TSw84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Counter(target_train))\n",
        "print(Counter(target_val))"
      ],
      "metadata": {
        "id": "IAMFHDFIVD1L"
      },
      "id": "IAMFHDFIVD1L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that we have $80\\%$ data ready for training and $20\\%$ for validation, both sets with a 2:1 target class ratio: job done!"
      ],
      "metadata": {
        "id": "mki_AVWuVGjh"
      },
      "id": "mki_AVWuVGjh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the neural network model\n",
        "\n",
        "We want to use a neural network model for logistic regression.\n",
        "There are many `Python` frameworks that implement (Deep) Neural Networks: here we are using `Keras` (for more details on how to use *keras* a good starting point is the [documentation on training and evaluation](https://www.tensorflow.org/guide/keras/train_and_evaluate)).\n",
        "\n",
        "Our neural network will be very minimal, as illustrated in the sketch at the beginning of this notebook: it will be comprised of only one node (neuron) that will perform both 1) the linear combination of weighted input variables + bias term; and 2) activate the result of step 1 with the sigmoid function to produce the probability of belonging to class \"1\" (or \"0\").\n",
        "\n",
        "We are now ready to build the NN (neural network) model!\n",
        "\n",
        "- model set-up\n",
        "- model architecture and compiling"
      ],
      "metadata": {
        "id": "ecoydX0bVgMx"
      },
      "id": "ecoydX0bVgMx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model set-up\n",
        "\n",
        "We first need to define some hyperparameters:\n",
        "\n",
        "1. activation function (`sigmoid`, this is a binary classification problem)\n",
        "2. optimizer (the algorithm that carries out forward and backpropagation to solve the model)\n",
        "3. the loss function (`binary cross-entropy`, again this is binary classification!)"
      ],
      "metadata": {
        "id": "JHec8oN7cxvy"
      },
      "id": "JHec8oN7cxvy"
    },
    {
      "cell_type": "code",
      "source": [
        "activation_function = 'sigmoid'\n",
        "optimizing_method = 'rmsprop'\n",
        "loss_function = 'binary_crossentropy'"
      ],
      "metadata": {
        "id": "_mPrv77YVSwo"
      },
      "id": "_mPrv77YVSwo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture\n",
        "\n",
        "This is a one-layer one-unit neural network model.\n",
        "The neural network is fully connected, meaning that the unit receives in input all features."
      ],
      "metadata": {
        "id": "HAbTw4oDdSMS"
      },
      "id": "HAbTw4oDdSMS"
    },
    {
      "cell_type": "code",
      "source": [
        "#we are building a \"sequential\" model, meaning that the data will\n",
        "#flow like INPUT -> ELABORATION -> OUTPUT. In particular, we will\n",
        "#not have any loops, i.e. our output will never be recycled as\n",
        "#input for the first layer\n",
        "from keras.models import Sequential\n",
        "\n",
        "#a \"dense\" layer is a layer were all the data coming in are connected\n",
        "#to all nodes (fully connected).\n",
        "#In our case there is only one node in the layer, and\n",
        "#it receives all the input features\n",
        "from keras.layers import Dense\n",
        "\n",
        "# 2-class logistic regression in Keras\n",
        "model = Sequential()\n",
        "model.add(Dense(units=1, activation='sigmoid', input_dim=features_train.shape[1]))\n",
        "\n",
        "#the model is declared, but we still need to compile it to actually\n",
        "#build all the data structures\n",
        "model.compile(optimizer=optimizing_method, loss=loss_function)"
      ],
      "metadata": {
        "id": "LlgkOZuudTvT"
      },
      "id": "LlgkOZuudTvT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the `.summary()` method we can take a look inside the model:"
      ],
      "metadata": {
        "id": "Awoe08PBd_HG"
      },
      "id": "Awoe08PBd_HG"
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "NKOLG-tWd6o5"
      },
      "id": "NKOLG-tWd6o5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are three trainable parameters (the weights for the two input variables, W1, W2, plus the bias term 'B'), and a single node.\n",
        "The output is a single number. Excellent."
      ],
      "metadata": {
        "id": "LQlHhEv7eHrC"
      },
      "id": "LQlHhEv7eHrC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the neural network model\n",
        "\n",
        "Now that the model has been built and compiled, we are ready to train it on the data.\n",
        "Training is an iterative process that cycles many times through what are called `epochs`. Remeber: one epoch is one cycle of forward and backward propagation.\n",
        "\n",
        "We'll start with only ten epochs, to get the gist of it (and we print out the standard output to monitor the process):"
      ],
      "metadata": {
        "id": "bMoZEu_phn7j"
      },
      "id": "bMoZEu_phn7j"
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(features_train, target_train, epochs=10, validation_data=(features_val, target_val))"
      ],
      "metadata": {
        "id": "OzRyL84ud7El"
      },
      "id": "OzRyL84ud7El",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We asked for ten epochs and the network did just that. At each iteration the network is trying really hard to minimize the [\"loss\"](https://keras.io/api/losses/). The specifics are defined by our choice of loss function (we selected `binary_crossentropy`). The basic idea is that the smaller the loss the better the fit.\n",
        "\n",
        "Note that the network minimizes the loss on the training set and does not use the validation set during the learning process. It can however measure the loss on the validation set to give us an idea on how well it can generalize on new data.\n",
        "\n",
        "It's handy at this point to define a function that takes in the `history` object returned by `.fit()` and plots it:"
      ],
      "metadata": {
        "id": "5gbvbxc6jmqa"
      },
      "id": "5gbvbxc6jmqa"
    },
    {
      "cell_type": "code",
      "source": [
        "#function to take a look at losses evolution\n",
        "def plot_loss_history(h, title):\n",
        "    plt.plot(h.history['loss'], label = \"Train loss\")\n",
        "    plt.plot(h.history['val_loss'], label = \"Validation loss\")\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "siu0zjjehvFf"
      },
      "id": "siu0zjjehvFf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_history(history, 'Logistic (10 epochs)')"
      ],
      "metadata": {
        "id": "pVKSJX8ShxPh"
      },
      "id": "pVKSJX8ShxPh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The good news is that the loss just goes down, both in train and validation set. We can keep training - without recompiling, we just add new epochs to our network."
      ],
      "metadata": {
        "id": "nwdeKHYpj4X_"
      },
      "id": "nwdeKHYpj4X_"
    },
    {
      "cell_type": "code",
      "source": [
        "#putting verbose to 0 to avoid filling the screen\n",
        "history2 = model.fit(features_train, target_train, epochs=190,\n",
        "                     validation_data=(features_val, target_val), verbose=0)"
      ],
      "metadata": {
        "id": "do6J-enfj8T1"
      },
      "id": "do6J-enfj8T1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if (and by how much) we improved our training:"
      ],
      "metadata": {
        "id": "mjjdxUj1kGNe"
      },
      "id": "mjjdxUj1kGNe"
    },
    {
      "cell_type": "code",
      "source": [
        "#putting together the whole history\n",
        "history.history['loss'] += history2.history['loss']\n",
        "history.history['val_loss'] += history2.history['val_loss']\n",
        "\n",
        "#and plotting again\n",
        "plot_loss_history(history, 'Logistic (500 epochs)')"
      ],
      "metadata": {
        "id": "Mg_MJ3q5kFdi"
      },
      "id": "Mg_MJ3q5kFdi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is very informative: the loss keeps decreasing, meaning that the network keeps improving. However after a first phase of steep improvement the gain for each epoch slows down considerably (diminishing returns).\n",
        "\n",
        "Additionally, we now see a clear difference between what happens in the training and in the validation sets. This means that, while the network keeps improving, its performance on new data is expected to be worse than that on the training data (as theoretically expected: training by the book!).\n",
        "\n",
        "We can now ask ourselves: what happens if we keep training for a long time? We have prepared the code for 10000 epochs, but it takes a long time to run, and it's faster if we simply show the saved results (but you can try to run it putting the following flag to `True`):"
      ],
      "metadata": {
        "id": "-rUceSeikP6c"
      },
      "id": "-rUceSeikP6c"
    },
    {
      "cell_type": "code",
      "source": [
        "do_10000_epochs = False"
      ],
      "metadata": {
        "id": "vtHe-PEWk1Za"
      },
      "id": "vtHe-PEWk1Za",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what happens if we keep going for a (very) long time?\n",
        "if (do_10000_epochs):\n",
        "    #train for 10000 epochs, just to show how the model evolves\n",
        "    history3 = model.fit(features_train, target_train, epochs=9500,\n",
        "                         validation_data=(features_val, target_val), verbose=0)\n",
        "\n",
        "    #putting together the whole history\n",
        "    history.history['loss'] += history3.history['loss']\n",
        "    history.history['val_loss'] += history3.history['val_loss']\n",
        "\n",
        "    #and plotting again\n",
        "    plot_loss_history(history, 'Logistic (10000 epochs)')"
      ],
      "metadata": {
        "id": "V3i5iLNUk5co"
      },
      "id": "V3i5iLNUk5co",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pre-recorded results look like this:\n",
        "\n",
        "![regression_10000_epochs](regression_loss10000.png)\n",
        "\n",
        "It appears that there is constant, slow improvement on the training set. Improvement on validation set is slower, and if we had the patience to go for a veeeery long time the orange curve would become completely flat."
      ],
      "metadata": {
        "id": "YhO2qhx4lCAc"
      },
      "id": "YhO2qhx4lCAc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation\n",
        "\n",
        "Any model is only useful when it's used to predict new, unknown data. In fact the whole validation set was put apart and not really used for training for this specific reason.\n",
        "\n",
        "There are several ways in which a neural network model (or any model for that matter!) can be evaluated.\n",
        "Here we look at a few approaches:\n",
        "\n",
        "- decision boundary\n",
        "- error-rate / accuracy\n",
        "- confusion matrix"
      ],
      "metadata": {
        "id": "brqzSW3wlmOp"
      },
      "id": "brqzSW3wlmOp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Boundary\n",
        "\n",
        "Based on the model fit, we can plot the decision boundary, i.e. a representation in the two-dimensional feature space of the criterion that the model is using to classify the data in the two classes (`virginica` and `non-virginica` flowers).\n",
        "For this task we'll use the [mlxtend module](http://rasbt.github.io/mlxtend/), which unfortunately does not usually come with the standard installation. Let's add it!"
      ],
      "metadata": {
        "id": "Q1tXDHkGmR13"
      },
      "id": "Q1tXDHkGmR13"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend ##execute shell command"
      ],
      "metadata": {
        "id": "kdfsi_Uvk9IO"
      },
      "id": "kdfsi_Uvk9IO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "#we'll print the training set\n",
        "plot_decision_regions(X = features_val.to_numpy(), y = target_val.to_numpy(), clf=model)\n",
        "plt.title('Decision boundary for 0 (non virginica) vs 1 (virginica) flowers')\n",
        "plt.xlabel(iris.feature_names[feature_x])\n",
        "plt.ylabel(iris.feature_names[feature_y])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vpoxza6DnNbP"
      },
      "id": "Vpoxza6DnNbP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The colored areas (yellow, blue) represent the behaviour of the trained model; the blue squares and yellow triangles are the actual samples in the validation set.\n",
        "\n",
        "The **decision boundary is linear**, as expected by logistic regression. This means that all samples in the pink area will be classified as 1 (virginica) and all points in the blue area be considered 0 (non virginica).\n",
        "\n",
        "Note that relatively many virginica samples are in the blue area compared to the numer of non-virginica present in the pink area. Also note that, roughly speaking, the regressor assigned a wider area to non-virginica. This is a direct consequence of having an unbalanced dataset: two-thirds of the samples are non-virginica (blue squares) and one-third are virginica (red triangles). **The resulting regressor is polarised** towards the more numerous class."
      ],
      "metadata": {
        "id": "F7ZHPR7BnYNY"
      },
      "id": "F7ZHPR7BnYNY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error rate / accuracy\n",
        "\n",
        "To calculate the accuracy of the trained neural network model for binary classification, we first need to get the predictions made on the validation set.\n",
        "Luckily, it's very easy to apply a trained model to new data (the validation set) via the [predict() method](https://keras.io/api/models/model_training_apis/#predict-method).\n",
        "\n",
        "We can thus get our prediction for the iris flowers (see below):"
      ],
      "metadata": {
        "id": "1tXXdV6m4pnK"
      },
      "id": "1tXXdV6m4pnK"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(features_val)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "Lzvgmz1noEbF"
      },
      "id": "Lzvgmz1noEbF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What do these numbers (the predictions) represent?** If you remember, in logistic regression we are modelling $P(y=1|x)$ (in short, $p(x)$), the probability for a sample of belonging to class \"1\" given the data `x`.\n",
        "\n",
        "If we use the **0.5 threshold** to assign samples to the two classes (a very natural choice), we will say that a sample belongs to class \"0\" (`non-virginica`) if $P(x) < 0.5$, or to class \"1\" (`virginica`) if $p(x) > 0.5$.\n",
        "\n",
        "Then, we can compare the predicted and true classes in the validation set and count the errors (remember, this is supervised learning, we know the \"answers\"!).\n"
      ],
      "metadata": {
        "id": "hrJVkUiy5hP-"
      },
      "id": "hrJVkUiy5hP-"
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class = np.where(predictions > 0.5, \"virginica\", \"non-virginica\")\n",
        "target_class = np.where(target_val == 1, \"virginica\", \"non-virginica\")\n",
        "target_class = target_class.reshape(len(target_class),1)\n",
        "\n",
        "results = target_class == predicted_class"
      ],
      "metadata": {
        "id": "FbgaBkeg6u5G"
      },
      "id": "FbgaBkeg6u5G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now count the number of errors and of correct predictions, and from these the error rate and the accuracy as simple ratios on the total number of predictions:"
      ],
      "metadata": {
        "id": "C3Oj8ubw8dkY"
      },
      "id": "C3Oj8ubw8dkY"
    },
    {
      "cell_type": "code",
      "source": [
        "errors = np.invert(results).sum()\n",
        "correct_predictions = results.sum()\n",
        "total_n_predictions = len(results)\n",
        "\n",
        "print(\"Error rate:\", round(errors/total_n_predictions, 3))\n",
        "print(\"Accuracy:\", round(correct_predictions/total_n_predictions, 3))"
      ],
      "metadata": {
        "id": "2Ky3UlRO7M3A"
      },
      "id": "2Ky3UlRO7M3A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix\n",
        "\n",
        "Besides the overall error rate / accuracy, it is always a good idea to look at the errors in the two classes.\n",
        "This is especially important when data are unbalanced. We can have a more comprehensive assessment of the performance of the classification model by looking at the **confusion matrix** (more details <a href=\"https://en.wikipedia.org/wiki/Confusion_matrix\">here</a>)."
      ],
      "metadata": {
        "id": "R3F37lm09MBY"
      },
      "id": "R3F37lm09MBY"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = ['non-virginica','virginica']\n",
        "con_mat_df = confusion_matrix( y_true = target_class, y_pred = predicted_class, labels=labels) #true are rows, predicted are columns\n",
        "pd.DataFrame(\n",
        "    con_mat_df,\n",
        "    index = ['true:'+x for x in labels],\n",
        "    columns = ['pred:'+x for x in labels])"
      ],
      "metadata": {
        "id": "rqL1KNu4-PgB"
      },
      "id": "rqL1KNu4-PgB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Along the diagonal of the confusion matrix we have the correct predictions, off the diagonal the errors.\n",
        "\n",
        "We see that 7 virginica flowers have been wrongly predicted as non-virginica flowers, and 3 non-virginica flowers have been wrongly predicted as virginica flowers.\n",
        "\n",
        "It is apparent that the unblancedness of the data has skewed predictions in favor of non-virginica flowers, the most common type of flowers in the data (twice as much).\n",
        "\n",
        "We can express this \"bias\" by measuring the accuracy in the two classes:\n",
        "\n",
        "- **True positive rate** (**TPR**): the proportion of correct predictions in the positive class (class `1`, here virginica) $\\rightarrow$ TP/(TP+FN) = 3/(3+7) = 3/10 = 0.333\n",
        "- **True negative rate** (**TNR**): the proportion of correct predictions in the negative class (class `0`, here non-virginica) $\\rightarrow$ TN/(TN+FP) = 17/(17+3) = 17/20 = 0.85"
      ],
      "metadata": {
        "id": "IZS1iwxv-9Eg"
      },
      "id": "IZS1iwxv-9Eg"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}