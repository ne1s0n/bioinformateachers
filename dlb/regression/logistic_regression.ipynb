{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "16f2f29e",
      "metadata": {
        "id": "16f2f29e"
      },
      "source": [
        "## One-unit neural network model for logistic regression\n",
        "\n",
        "In this notebook, we illustrate how to do [logistic regression](https://en.wikipedia.org/wiki/Logistic_regression)\n",
        "using a neural network-like implementation with one single unit (perceptron).\n",
        "This is equivalent to a logistic regression model, only it is solved using neural networks (forward and backpropagation) rather than with maximum likelihood (or similar algorithms).\n",
        "\n",
        "As example data, we use the famous [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6deb0024",
      "metadata": {
        "id": "6deb0024"
      },
      "source": [
        "Basically, a neural network implementation of logistic regression will look like the sketch below: first, the vector of input features $\\mathbf{x}$ is multiplied by the vector of weights $\\mathbf{w}$, the results are summed up together and the bias term $b$ is added. This will return the real-valued variable $z$ in the interval $[\\pm âˆž]$.\n",
        "Then, $z$ is activated with the logistic (sigmoid) function $\\rightarrow \\sigma(z)$ to give $P(y=1|x)$, the probability of belonging to class `1` given the input features $x$.\n",
        "\n",
        "<img src=\"logistic_perceptron.png\" alt=\"perceptron\" style=\"width: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries and setting the random seed\n",
        "\n",
        "First of all, we load some necessary libraries; then we setup the random seed to ensure reproducibility of results. Since tensorflow uses an internal random generator we need to fix both the general seed (via numpy `seed()`) and tensorflow seed (via `set_seet()`)"
      ],
      "metadata": {
        "id": "5Z63YlH0OgfH"
      },
      "id": "5Z63YlH0OgfH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e86c1bf",
      "metadata": {
        "id": "9e86c1bf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "  # Set the seed using keras.utils.set_random_seed. This will set:\n",
        "  # 1) `numpy` seed\n",
        "  # 2) `tensorflow` random seed\n",
        "  # 3) `python` random seed\n",
        "tf.keras.utils.set_random_seed(10)\n",
        "\n",
        "  # This will make TensorFlow ops as deterministic as possible, but it will\n",
        "  # affect the overall performance, so it's not enabled by default.\n",
        "  # `enable_op_determinism()` is introduced in TensorFlow 2.9.\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "From `sklearn.datasets` there are generally two ways to import the data:\n",
        "\n",
        "1. `return_X_y = False` (default): returns a \"bunch\" object that contains both the `target` and the `features` (to be accessed as attributes): `<dataset>.target` and `<dataset>.data`\n",
        "2. `return_X_y = True`: returns directly the target and features separately"
      ],
      "metadata": {
        "id": "zZ3vzxq4B0IQ"
      },
      "id": "zZ3vzxq4B0IQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09318d92",
      "metadata": {
        "id": "09318d92"
      },
      "outputs": [],
      "source": [
        "import sklearn.datasets\n",
        "\n",
        "## 1)\n",
        "iris = sklearn.datasets.load_iris()\n",
        "features = iris.data\n",
        "target = iris.target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2)\n",
        "(features_, target_) = sklearn.datasets.load_iris(return_X_y = True) ## feature names are not returned"
      ],
      "metadata": {
        "id": "2grViWP-Cze8"
      },
      "id": "2grViWP-Cze8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target == target_"
      ],
      "metadata": {
        "id": "FQGnQL1eDOsx"
      },
      "id": "FQGnQL1eDOsx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we convert data and features (originally as `numpy` arrays) to `pandas` dataframes / series"
      ],
      "metadata": {
        "id": "1rStMQUKDmt-"
      },
      "id": "1rStMQUKDmt-"
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data = pd.DataFrame(features, columns=iris.feature_names) #converting numpy array -> pandas DataFrame\n",
        "iris.target = pd.Series(target) #converting numpy array -> pandas Series"
      ],
      "metadata": {
        "id": "6jEcpPgtDDYh"
      },
      "id": "6jEcpPgtDDYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **iris** dataset is a historic dataset first used by **Ronald Fisher** in his 1936 paper on linear discriminant analysis (LDA).\n",
        "The dataset contains information on 150 flower samples, belonging to three species of Iris (Iris setosa, Iris virginica and Iris versicolor: the `target`).\n",
        "Four `features` were measured from each sample: the length and the width of the sepals and of the petals, in centimeters."
      ],
      "metadata": {
        "id": "Bpq4XO6UI_ta"
      },
      "id": "Bpq4XO6UI_ta"
    },
    {
      "cell_type": "code",
      "source": [
        "print(iris.DESCR)"
      ],
      "metadata": {
        "id": "zPHqRATEErQ-"
      },
      "id": "zPHqRATEErQ-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "As said, the feature data has 150 rown and 4 columns:"
      ],
      "metadata": {
        "id": "FQp5ITO0KXKF"
      },
      "id": "FQp5ITO0KXKF"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of the feature table: ' + str(iris.data.shape))"
      ],
      "metadata": {
        "id": "BaEeW57GKZ9E"
      },
      "id": "BaEeW57GKZ9E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The four features are real-valued numbers in the $10^1$ range:"
      ],
      "metadata": {
        "id": "5aduLrMQK8cG"
      },
      "id": "5aduLrMQK8cG"
    },
    {
      "cell_type": "code",
      "source": [
        "iris.data.describe()"
      ],
      "metadata": {
        "id": "LQPPnwo3KvYE"
      },
      "id": "LQPPnwo3KvYE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `target` is a vector (`pandas` series) of integers (0, 1, 2), one for each flower species (50 samples each):"
      ],
      "metadata": {
        "id": "Gr_okx7eLJ_t"
      },
      "id": "Gr_okx7eLJ_t"
    },
    {
      "cell_type": "code",
      "source": [
        "#using Counter object to print a tally of the classes\n",
        "from collections import Counter\n",
        "print('Numerosity for each class: ' + str(Counter(iris.target)))"
      ],
      "metadata": {
        "id": "dZme8IZ0LF6R"
      },
      "id": "dZme8IZ0LF6R",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}